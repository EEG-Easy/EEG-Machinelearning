{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P300RobustScaling",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJxxLjZ3LeZ5ufqx5DR/Vp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EEG-Easy/EEG-Machinelearning/blob/master/2020-2Project/2_%EB%94%A5%EB%9F%AC%EB%8B%9D/P300RobustScaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht-vy4_HUFoZ",
        "colab_type": "code",
        "outputId": "f0eee61d-4088-4a5d-9446-a189ce54a082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2y4teP29OrJ",
        "colab_type": "code",
        "outputId": "30558bc0-acd5-46af-8853-33a6954defb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY4Cc6rA9TLI",
        "colab_type": "code",
        "outputId": "154f375b-09a0-48cd-e37b-24ff80903357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/eeg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/eeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsRzazJ89V7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EEG_df = pd.read_csv('P300.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMlaMUfy9X6J",
        "colab_type": "code",
        "outputId": "ab6c8adc-1993-4763-e68a-e38cd610d0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "EEG_df.pop('subject')\n",
        "EEG_df.pop('trial')\n",
        "EEG_df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['condition', 'group', 'F1_P300', 'FC3_P300', 'FC1_P300', 'AFz_P300',\n",
              "       'Fz_P300', 'F2_P300', 'FCz_P300'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wKodYXX9aaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "condition=np.array(EEG_df['condition'])\n",
        "group=np.array(EEG_df['group'])\n",
        "\n",
        "EEG_scaling = EEG_df.drop(['condition', 'group'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SeCs4mH96Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = RobustScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFD9raef-H_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler.fit(EEG_scaling) \n",
        "EEG_scaled = scaler.transform(EEG_scaling)\n",
        "EEG_scaled_df = pd.DataFrame(EEG_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66tF98hc-SIl",
        "colab_type": "code",
        "outputId": "de7821d7-bee2-4364-f098-b417e42ed25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "EEG_scaled_df.columns = ['F1', 'FC3', 'FC1', 'AFz', 'Fz', 'F2', 'FCz']\n",
        "EEG_scaled_df['condition'] = condition\n",
        "EEG_scaled_df['group'] = group\n",
        "EEG_scaled_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>FC3</th>\n",
              "      <th>FC1</th>\n",
              "      <th>AFz</th>\n",
              "      <th>Fz</th>\n",
              "      <th>F2</th>\n",
              "      <th>FCz</th>\n",
              "      <th>condition</th>\n",
              "      <th>group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.193157</td>\n",
              "      <td>-0.093217</td>\n",
              "      <td>-0.139332</td>\n",
              "      <td>-0.014351</td>\n",
              "      <td>-0.482007</td>\n",
              "      <td>-0.612296</td>\n",
              "      <td>-0.432072</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.887894</td>\n",
              "      <td>1.593248</td>\n",
              "      <td>1.007132</td>\n",
              "      <td>0.268088</td>\n",
              "      <td>0.678681</td>\n",
              "      <td>1.014418</td>\n",
              "      <td>1.029642</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.254117</td>\n",
              "      <td>0.390429</td>\n",
              "      <td>0.204192</td>\n",
              "      <td>-0.012284</td>\n",
              "      <td>0.633721</td>\n",
              "      <td>0.676659</td>\n",
              "      <td>0.360667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.415138</td>\n",
              "      <td>0.628633</td>\n",
              "      <td>1.080357</td>\n",
              "      <td>0.549231</td>\n",
              "      <td>0.658604</td>\n",
              "      <td>0.430925</td>\n",
              "      <td>0.769865</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.608327</td>\n",
              "      <td>-0.192824</td>\n",
              "      <td>-0.775245</td>\n",
              "      <td>-0.364559</td>\n",
              "      <td>-0.693839</td>\n",
              "      <td>-0.516647</td>\n",
              "      <td>-0.817077</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         F1       FC3       FC1       AFz  ...        F2       FCz  condition  group\n",
              "0 -0.193157 -0.093217 -0.139332 -0.014351  ... -0.612296 -0.432072          1      0\n",
              "1  0.887894  1.593248  1.007132  0.268088  ...  1.014418  1.029642          1      0\n",
              "2  0.254117  0.390429  0.204192 -0.012284  ...  0.676659  0.360667          1      0\n",
              "3  0.415138  0.628633  1.080357  0.549231  ...  0.430925  0.769865          1      0\n",
              "4 -0.608327 -0.192824 -0.775245 -0.364559  ... -0.516647 -0.817077          1      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5a57rCp-dWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EEG_scaled_df.to_csv('/content/gdrive/My Drive/eeg/RobustP300.csv',sep=',', na_rep='NaN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9VQKMLr-ppa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'group'\n",
        "LABELS = [0, 1]\n",
        "\n",
        "CSV_COLUMNS = ['condition','group', 'F1', 'FC3', 'FC1', 'AFz', 'Fz', 'F2', 'FCz']\n",
        "\n",
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=5, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True, \n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "temp_dataset = get_dataset('RobustP300.csv', select_columns=CSV_COLUMNS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-DyMXHk-rzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX0XTMi7-up5",
        "colab_type": "code",
        "outputId": "557ecd8c-cd16-4009-b063-8050221be00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "NUMERIC_FEATURES = ['F1', 'FC3', 'FC1', 'AFz', 'Fz', 'F2', 'FCz']\n",
        "\n",
        "packed_data = temp_dataset.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method PackNumericFeatures.__call__ of <__main__.PackNumericFeatures object at 0x7efc5a8f1470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: No module named 'tensorflow_core.estimator'\n",
            "WARNING: AutoGraph could not transform <bound method PackNumericFeatures.__call__ of <__main__.PackNumericFeatures object at 0x7efc5a8f1470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: No module named 'tensorflow_core.estimator'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnj-p-Xd-wyz",
        "colab_type": "code",
        "outputId": "37ac5c97-2087-4c6f-9012-67f99c57ddbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "import pandas as pd\n",
        "desc = EEG_scaled_df[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>FC3</th>\n",
              "      <th>FC1</th>\n",
              "      <th>AFz</th>\n",
              "      <th>Fz</th>\n",
              "      <th>F2</th>\n",
              "      <th>FCz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.169534</td>\n",
              "      <td>0.147238</td>\n",
              "      <td>0.125680</td>\n",
              "      <td>0.257439</td>\n",
              "      <td>0.161898</td>\n",
              "      <td>0.181233</td>\n",
              "      <td>0.115794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.137716</td>\n",
              "      <td>1.068238</td>\n",
              "      <td>1.004288</td>\n",
              "      <td>1.523621</td>\n",
              "      <td>1.147731</td>\n",
              "      <td>1.186636</td>\n",
              "      <td>0.957781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-8.638409</td>\n",
              "      <td>-7.128760</td>\n",
              "      <td>-6.194677</td>\n",
              "      <td>-10.138734</td>\n",
              "      <td>-7.300168</td>\n",
              "      <td>-7.736735</td>\n",
              "      <td>-6.063609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.450238</td>\n",
              "      <td>-0.453220</td>\n",
              "      <td>-0.460870</td>\n",
              "      <td>-0.440929</td>\n",
              "      <td>-0.455397</td>\n",
              "      <td>-0.448035</td>\n",
              "      <td>-0.462869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.549762</td>\n",
              "      <td>0.546780</td>\n",
              "      <td>0.539130</td>\n",
              "      <td>0.559071</td>\n",
              "      <td>0.544603</td>\n",
              "      <td>0.551965</td>\n",
              "      <td>0.537131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.795594</td>\n",
              "      <td>20.475962</td>\n",
              "      <td>24.351948</td>\n",
              "      <td>25.661585</td>\n",
              "      <td>17.733415</td>\n",
              "      <td>16.691511</td>\n",
              "      <td>13.711209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 F1           FC3  ...            F2           FCz\n",
              "count  23201.000000  23201.000000  ...  23201.000000  23201.000000\n",
              "mean       0.169534      0.147238  ...      0.181233      0.115794\n",
              "std        1.137716      1.068238  ...      1.186636      0.957781\n",
              "min       -8.638409     -7.128760  ...     -7.736735     -6.063609\n",
              "25%       -0.450238     -0.453220  ...     -0.448035     -0.462869\n",
              "50%        0.000000      0.000000  ...      0.000000      0.000000\n",
              "75%        0.549762      0.546780  ...      0.551965      0.537131\n",
              "max       17.795594     20.475962  ...     16.691511     13.711209\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g83t5QX_-yWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC2rpDt1--KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg4oPvmg-_xq",
        "colab_type": "code",
        "outputId": "643cc058-0d99-4b9f-97ae-9095e7ed4707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(7,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7efc5a8ddd08>, mean=array([0.16953369, 0.14723849, 0.1256803 , 0.25743903, 0.16189793,\n",
              "       0.18123256, 0.11579391]), std=array([1.13771572, 1.06823785, 1.00428802, 1.52362056, 1.14773099,\n",
              "       1.18663606, 0.95778078])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Z-96Sn_BQP",
        "colab_type": "code",
        "outputId": "03a369ea-ea6c-4ba1-bb3d-03624b921e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "example_batch, labels_batch = next(iter(packed_data)) \n",
        "example_batch['numeric']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 7), dtype=float32, numpy=\n",
              "array([[-0.73736995, -1.0586225 , -0.76923674, -0.7760385 , -0.79601073,\n",
              "        -0.9157964 , -1.6266463 ],\n",
              "       [-0.00393089, -0.19127612, -0.29434994,  0.05472529, -0.11946619,\n",
              "         0.14347596, -0.2100413 ],\n",
              "       [-0.31780148,  0.32996264,  0.14018953,  0.09033884, -0.37287387,\n",
              "        -0.38955414,  0.38241202],\n",
              "       [-0.19593135,  0.448088  ,  0.13790326,  0.05126667, -0.14704439,\n",
              "         0.10892434,  0.22845288],\n",
              "       [-0.531504  , -0.26355326, -1.2163053 , -0.4796184 , -0.61335254,\n",
              "        -0.68536085, -0.9029014 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DemqAHsu_Dcy",
        "colab_type": "code",
        "outputId": "ee96b1c1-4694-477c-9f08-1b7e876c8dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.79712677, -1.1288319 , -0.89109594, -0.6783037 , -0.83461076,\n",
              "        -0.92448646, -1.8192475 ],\n",
              "       [-0.15246741, -0.31689066, -0.4182368 , -0.13304737, -0.24514815,\n",
              "        -0.03181817, -0.3401981 ],\n",
              "       [-0.42834526,  0.17105192,  0.01444728, -0.10967309, -0.4659383 ,\n",
              "        -0.48101243,  0.2783707 ],\n",
              "       [-0.32122704,  0.28163156,  0.01217077, -0.13531739, -0.2691766 ,\n",
              "        -0.06093546,  0.11762501],\n",
              "       [-0.61618   , -0.3845508 , -1.3362557 , -0.48375392, -0.67546356,\n",
              "        -0.73029417, -1.0635997 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uLGiiVj_Dx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORIES = {'condition': [1, 2, 3]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0FM0FlN_I2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG-l3-fg_KcN",
        "colab_type": "code",
        "outputId": "ef689fe6-f927-4fc7-abe8-c97ec9f2152f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "[0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHjIFguB_MWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns) #+numeric_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UsA8BWJ_Pjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer, # 256,256 / 128,256\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  #tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C95aCECb_RV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(20000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2IaQFaB_UkO",
        "colab_type": "code",
        "outputId": "5d4d2287-e622-493e-ea98-674f93e657f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "history=model.fit(train_data, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 [==============================] - 25s 5ms/step - loss: 0.6708 - accuracy: 0.6017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxlvn-0YSk6j",
        "colab_type": "code",
        "outputId": "7611f73f-c41d-44c5-e575-ba6dc8eb3d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()\n",
        "model.save('model1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_features_2 (DenseFeatu multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  1408      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  33024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  257       \n",
            "=================================================================\n",
            "Total params: 34,689\n",
            "Trainable params: 34,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-39-1d7412db98ae>\", line 2, in <module>\n",
            "    model.save('model1.h5')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 1008, in save\n",
            "    signatures, options)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py\", line 112, in save_model\n",
            "    model, filepath, overwrite, include_optimizer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 99, in save_model_to_hdf5\n",
            "    model_metadata = saving_utils.model_metadata(model, include_optimizer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saving_utils.py\", line 169, in model_metadata\n",
            "    model_config['config'] = model.get_config()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py\", line 347, in get_config\n",
            "    layer_configs.append(generic_utils.serialize_keras_object(layer))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 198, in serialize_keras_object\n",
            "    config = instance.get_config()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py\", line 439, in get_config\n",
            "    self._feature_columns)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/serialization.py\", line 166, in serialize_feature_columns\n",
            "    return [serialize_feature_column(fc) for fc in feature_columns]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/serialization.py\", line 166, in <listcomp>\n",
            "    return [serialize_feature_column(fc) for fc in feature_columns]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/serialization.py\", line 88, in serialize_feature_column\n",
            "    fc.__class__.__name__, fc.get_config())  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py\", line 2870, in get_config\n",
            "    self.normalizer_fn)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 219, in serialize_keras_object\n",
            "    raise ValueError('Cannot serialize', instance)\n",
            "ValueError: ('Cannot serialize', functools.partial(<function normalize_numeric_data at 0x7efc5a8ddd08>, mean=array([0.16953369, 0.14723849, 0.1256803 , 0.25743903, 0.16189793,\n",
            "       0.18123256, 0.11579391]), std=array([1.13771572, 1.06823785, 1.00428802, 1.52362056, 1.14773099,\n",
            "       1.18663606, 0.95778078])))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmpC1UAiJxAe",
        "colab_type": "code",
        "outputId": "a36afc0f-4e27-47a6-c40c-f17b7b033c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 [==============================] - 19s 4ms/step - loss: 0.5333 - acc: 0.7847\n",
            "\n",
            "\n",
            "Test Loss 0.5332511613264577, Test Accuracy 0.7847075462341309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHM9Eb3vEU6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "#model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMOmsjrxfW65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(15000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGGAfbl7GdW2",
        "colab_type": "code",
        "outputId": "b0f41b6a-6591-4511-eeac-5f2b252960cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4641/4641 [==============================] - 23s 5ms/step - loss: 0.5100 - acc: 0.7814\n",
            "Epoch 2/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4426 - acc: 0.7880\n",
            "Epoch 3/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4276 - acc: 0.7912\n",
            "Epoch 4/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4440 - acc: 0.7902\n",
            "Epoch 5/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4312 - acc: 0.7913\n",
            "Epoch 6/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4291 - acc: 0.7938\n",
            "Epoch 7/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4102 - acc: 0.7963\n",
            "Epoch 8/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4287 - acc: 0.7943\n",
            "Epoch 9/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4074 - acc: 0.8005\n",
            "Epoch 10/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.4173 - acc: 0.7985\n",
            "Epoch 11/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3900 - acc: 0.8038\n",
            "Epoch 12/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4084 - acc: 0.8010\n",
            "Epoch 13/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4013 - acc: 0.8038\n",
            "Epoch 14/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3922 - acc: 0.8064\n",
            "Epoch 15/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3949 - acc: 0.8033\n",
            "Epoch 16/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3857 - acc: 0.8088\n",
            "Epoch 17/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3836 - acc: 0.8085\n",
            "Epoch 18/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3951 - acc: 0.8036\n",
            "Epoch 19/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3835 - acc: 0.8101\n",
            "Epoch 20/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3793 - acc: 0.8108\n",
            "Epoch 21/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3760 - acc: 0.8103\n",
            "Epoch 22/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3833 - acc: 0.8097\n",
            "Epoch 23/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3772 - acc: 0.8139\n",
            "Epoch 24/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3748 - acc: 0.8110\n",
            "Epoch 25/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3843 - acc: 0.8116\n",
            "Epoch 26/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3715 - acc: 0.8144\n",
            "Epoch 27/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3735 - acc: 0.8145\n",
            "Epoch 28/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3713 - acc: 0.8120\n",
            "Epoch 29/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3719 - acc: 0.8141\n",
            "Epoch 30/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3772 - acc: 0.8120\n",
            "Epoch 31/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3775 - acc: 0.8137\n",
            "Epoch 32/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3874 - acc: 0.8123\n",
            "Epoch 33/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3717 - acc: 0.8183\n",
            "Epoch 34/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3669 - acc: 0.8162\n",
            "Epoch 35/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3566 - acc: 0.8178\n",
            "Epoch 36/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3715 - acc: 0.8188\n",
            "Epoch 37/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.3618 - acc: 0.8227\n",
            "Epoch 38/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3628 - acc: 0.8161\n",
            "Epoch 39/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3567 - acc: 0.8191\n",
            "Epoch 40/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3560 - acc: 0.8232\n",
            "Epoch 41/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3563 - acc: 0.8207\n",
            "Epoch 42/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3547 - acc: 0.8233\n",
            "Epoch 43/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3551 - acc: 0.8226\n",
            "Epoch 44/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3573 - acc: 0.8206\n",
            "Epoch 45/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3534 - acc: 0.8229\n",
            "Epoch 46/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3443 - acc: 0.8250\n",
            "Epoch 47/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3622 - acc: 0.8197\n",
            "Epoch 48/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3474 - acc: 0.8240\n",
            "Epoch 49/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3555 - acc: 0.8241\n",
            "Epoch 50/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3488 - acc: 0.8222\n",
            "Epoch 51/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3533 - acc: 0.8241\n",
            "Epoch 52/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3476 - acc: 0.8276\n",
            "Epoch 53/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3552 - acc: 0.8248\n",
            "Epoch 54/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3508 - acc: 0.8244\n",
            "Epoch 55/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3424 - acc: 0.8255\n",
            "Epoch 56/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3558 - acc: 0.8241\n",
            "Epoch 57/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3564 - acc: 0.8281\n",
            "Epoch 58/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3343 - acc: 0.8317\n",
            "Epoch 59/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3456 - acc: 0.8259\n",
            "Epoch 60/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3513 - acc: 0.8249\n",
            "Epoch 61/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3404 - acc: 0.8326\n",
            "Epoch 62/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3407 - acc: 0.8307\n",
            "Epoch 63/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3456 - acc: 0.8282\n",
            "Epoch 64/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3509 - acc: 0.8304\n",
            "Epoch 65/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3505 - acc: 0.8297\n",
            "Epoch 66/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3411 - acc: 0.8313\n",
            "Epoch 67/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3393 - acc: 0.8304\n",
            "Epoch 68/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3410 - acc: 0.8316\n",
            "Epoch 69/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3405 - acc: 0.8316\n",
            "Epoch 70/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3361 - acc: 0.8337\n",
            "Epoch 71/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3328 - acc: 0.8347\n",
            "Epoch 72/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3350 - acc: 0.8344\n",
            "Epoch 73/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3426 - acc: 0.8303\n",
            "Epoch 74/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3224 - acc: 0.8372\n",
            "Epoch 75/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3299 - acc: 0.8366\n",
            "Epoch 76/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3391 - acc: 0.8318\n",
            "Epoch 77/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3536 - acc: 0.8289\n",
            "Epoch 78/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3339 - acc: 0.8344\n",
            "Epoch 79/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3261 - acc: 0.8369\n",
            "Epoch 80/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3383 - acc: 0.8329\n",
            "Epoch 81/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3341 - acc: 0.8371\n",
            "Epoch 82/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3282 - acc: 0.8376\n",
            "Epoch 83/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3467 - acc: 0.8322\n",
            "Epoch 84/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3347 - acc: 0.8363\n",
            "Epoch 85/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3272 - acc: 0.8390\n",
            "Epoch 86/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3310 - acc: 0.8348\n",
            "Epoch 87/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3241 - acc: 0.8381\n",
            "Epoch 88/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3344 - acc: 0.8361\n",
            "Epoch 89/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3231 - acc: 0.8372\n",
            "Epoch 90/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3253 - acc: 0.8389\n",
            "Epoch 91/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3200 - acc: 0.8407\n",
            "Epoch 92/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3290 - acc: 0.8397\n",
            "Epoch 93/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3278 - acc: 0.8384\n",
            "Epoch 94/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3248 - acc: 0.8402\n",
            "Epoch 95/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3326 - acc: 0.8379\n",
            "Epoch 96/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3267 - acc: 0.8395\n",
            "Epoch 97/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3262 - acc: 0.8366\n",
            "Epoch 98/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3176 - acc: 0.8401\n",
            "Epoch 99/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3306 - acc: 0.8400\n",
            "Epoch 100/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3358 - acc: 0.8391\n",
            "Epoch 101/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3215 - acc: 0.8412\n",
            "Epoch 102/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3196 - acc: 0.8445\n",
            "Epoch 103/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3200 - acc: 0.8416\n",
            "Epoch 104/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3204 - acc: 0.8436\n",
            "Epoch 105/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3298 - acc: 0.8421\n",
            "Epoch 106/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3182 - acc: 0.8427\n",
            "Epoch 107/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3232 - acc: 0.8430\n",
            "Epoch 108/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3180 - acc: 0.8419\n",
            "Epoch 109/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3265 - acc: 0.8383\n",
            "Epoch 110/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3142 - acc: 0.8445\n",
            "Epoch 111/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3128 - acc: 0.8419\n",
            "Epoch 112/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3285 - acc: 0.8408\n",
            "Epoch 113/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3251 - acc: 0.8429\n",
            "Epoch 114/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3268 - acc: 0.8413\n",
            "Epoch 115/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3274 - acc: 0.8429\n",
            "Epoch 116/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3331 - acc: 0.8409\n",
            "Epoch 117/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3209 - acc: 0.8418\n",
            "Epoch 118/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3153 - acc: 0.8437\n",
            "Epoch 119/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.3156 - acc: 0.8459\n",
            "Epoch 120/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3236 - acc: 0.8453\n",
            "Epoch 121/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3119 - acc: 0.8447\n",
            "Epoch 122/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3156 - acc: 0.8443\n",
            "Epoch 123/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3155 - acc: 0.8449\n",
            "Epoch 124/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3071 - acc: 0.8470\n",
            "Epoch 125/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3226 - acc: 0.8460\n",
            "Epoch 126/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3241 - acc: 0.8447\n",
            "Epoch 127/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3151 - acc: 0.8472\n",
            "Epoch 128/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3198 - acc: 0.8434\n",
            "Epoch 129/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3195 - acc: 0.8459\n",
            "Epoch 130/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3115 - acc: 0.8468\n",
            "Epoch 131/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3060 - acc: 0.8479\n",
            "Epoch 132/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3097 - acc: 0.8494\n",
            "Epoch 133/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3110 - acc: 0.8470\n",
            "Epoch 134/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3103 - acc: 0.8478\n",
            "Epoch 135/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3255 - acc: 0.8449\n",
            "Epoch 136/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3035 - acc: 0.8495\n",
            "Epoch 137/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3413 - acc: 0.8397\n",
            "Epoch 138/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3196 - acc: 0.8472\n",
            "Epoch 139/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3007 - acc: 0.8504\n",
            "Epoch 140/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3226 - acc: 0.8440\n",
            "Epoch 141/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3069 - acc: 0.8492\n",
            "Epoch 142/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3076 - acc: 0.8465\n",
            "Epoch 143/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3133 - acc: 0.8487\n",
            "Epoch 144/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3022 - acc: 0.8504\n",
            "Epoch 145/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3065 - acc: 0.8508\n",
            "Epoch 146/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3097 - acc: 0.8488\n",
            "Epoch 147/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3005 - acc: 0.8505\n",
            "Epoch 148/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3085 - acc: 0.8491\n",
            "Epoch 149/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3445 - acc: 0.8443\n",
            "Epoch 150/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3045 - acc: 0.8507\n",
            "Epoch 151/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2983 - acc: 0.8538\n",
            "Epoch 152/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3245 - acc: 0.8433\n",
            "Epoch 153/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3124 - acc: 0.8496\n",
            "Epoch 154/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3031 - acc: 0.8522\n",
            "Epoch 155/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3194 - acc: 0.8475\n",
            "Epoch 156/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3084 - acc: 0.8496\n",
            "Epoch 157/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3167 - acc: 0.8477\n",
            "Epoch 158/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3066 - acc: 0.8510\n",
            "Epoch 159/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3101 - acc: 0.8492\n",
            "Epoch 160/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3124 - acc: 0.8500\n",
            "Epoch 161/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3046 - acc: 0.8530\n",
            "Epoch 162/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3082 - acc: 0.8526\n",
            "Epoch 163/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2996 - acc: 0.8521\n",
            "Epoch 164/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3145 - acc: 0.8511\n",
            "Epoch 165/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2986 - acc: 0.8543\n",
            "Epoch 166/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3349 - acc: 0.8466\n",
            "Epoch 167/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2999 - acc: 0.8534\n",
            "Epoch 168/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2913 - acc: 0.8566\n",
            "Epoch 169/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3038 - acc: 0.8510\n",
            "Epoch 170/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2941 - acc: 0.8566\n",
            "Epoch 171/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3137 - acc: 0.8493\n",
            "Epoch 172/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3137 - acc: 0.8509\n",
            "Epoch 173/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3089 - acc: 0.8529\n",
            "Epoch 174/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3046 - acc: 0.8537\n",
            "Epoch 175/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2937 - acc: 0.8569\n",
            "Epoch 176/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3053 - acc: 0.8532\n",
            "Epoch 177/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3034 - acc: 0.8548\n",
            "Epoch 178/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3052 - acc: 0.8526\n",
            "Epoch 179/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2993 - acc: 0.8537\n",
            "Epoch 180/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3036 - acc: 0.8531\n",
            "Epoch 181/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2953 - acc: 0.8563\n",
            "Epoch 182/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3020 - acc: 0.8546\n",
            "Epoch 183/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3197 - acc: 0.8489\n",
            "Epoch 184/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3080 - acc: 0.8528\n",
            "Epoch 185/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3188 - acc: 0.8494\n",
            "Epoch 186/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3010 - acc: 0.8570\n",
            "Epoch 187/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2840 - acc: 0.8619\n",
            "Epoch 188/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3125 - acc: 0.8557\n",
            "Epoch 189/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3093 - acc: 0.8533\n",
            "Epoch 190/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2880 - acc: 0.8597\n",
            "Epoch 191/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2981 - acc: 0.8563\n",
            "Epoch 192/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3132 - acc: 0.8529\n",
            "Epoch 193/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2924 - acc: 0.8602\n",
            "Epoch 194/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2969 - acc: 0.8563\n",
            "Epoch 195/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2784 - acc: 0.8602\n",
            "Epoch 196/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2952 - acc: 0.8561\n",
            "Epoch 197/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2889 - acc: 0.8603\n",
            "Epoch 198/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3076 - acc: 0.8542\n",
            "Epoch 199/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2982 - acc: 0.8545\n",
            "Epoch 200/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3202 - acc: 0.8530\n",
            "Epoch 201/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2927 - acc: 0.8588\n",
            "Epoch 202/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2945 - acc: 0.8589\n",
            "Epoch 203/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3073 - acc: 0.8538\n",
            "Epoch 204/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3054 - acc: 0.8551\n",
            "Epoch 205/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2942 - acc: 0.8580\n",
            "Epoch 206/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2955 - acc: 0.8570\n",
            "Epoch 207/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2944 - acc: 0.8582\n",
            "Epoch 208/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3228 - acc: 0.8525\n",
            "Epoch 209/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3077 - acc: 0.8548\n",
            "Epoch 210/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3059 - acc: 0.8585\n",
            "Epoch 211/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2911 - acc: 0.8575\n",
            "Epoch 212/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3007 - acc: 0.8560\n",
            "Epoch 213/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3017 - acc: 0.8568\n",
            "Epoch 214/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3032 - acc: 0.8562\n",
            "Epoch 215/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2972 - acc: 0.8596\n",
            "Epoch 216/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2905 - acc: 0.8595\n",
            "Epoch 217/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3158 - acc: 0.8516\n",
            "Epoch 218/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2953 - acc: 0.8599\n",
            "Epoch 219/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2880 - acc: 0.8592\n",
            "Epoch 220/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2973 - acc: 0.8588\n",
            "Epoch 221/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2948 - acc: 0.8590\n",
            "Epoch 222/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2960 - acc: 0.8597\n",
            "Epoch 223/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2904 - acc: 0.8600\n",
            "Epoch 224/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3142 - acc: 0.8557\n",
            "Epoch 225/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2923 - acc: 0.8600\n",
            "Epoch 226/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2925 - acc: 0.8582\n",
            "Epoch 227/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3005 - acc: 0.8580\n",
            "Epoch 228/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2964 - acc: 0.8602\n",
            "Epoch 229/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3051 - acc: 0.8590\n",
            "Epoch 230/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2824 - acc: 0.8607\n",
            "Epoch 231/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2884 - acc: 0.8606\n",
            "Epoch 232/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2999 - acc: 0.8608\n",
            "Epoch 233/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2924 - acc: 0.8616\n",
            "Epoch 234/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2910 - acc: 0.8594\n",
            "Epoch 235/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2851 - acc: 0.8612\n",
            "Epoch 236/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2981 - acc: 0.8590\n",
            "Epoch 237/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2716 - acc: 0.8642\n",
            "Epoch 238/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2956 - acc: 0.8582\n",
            "Epoch 239/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2991 - acc: 0.8561\n",
            "Epoch 240/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2893 - acc: 0.8626\n",
            "Epoch 241/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2876 - acc: 0.8607\n",
            "Epoch 242/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3036 - acc: 0.8584\n",
            "Epoch 243/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3192 - acc: 0.8528\n",
            "Epoch 244/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2991 - acc: 0.8604\n",
            "Epoch 245/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2999 - acc: 0.8583\n",
            "Epoch 246/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2927 - acc: 0.8626\n",
            "Epoch 247/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2904 - acc: 0.8594\n",
            "Epoch 248/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2959 - acc: 0.8592\n",
            "Epoch 249/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2847 - acc: 0.8635\n",
            "Epoch 250/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3026 - acc: 0.8597\n",
            "Epoch 251/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2837 - acc: 0.8636\n",
            "Epoch 252/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2924 - acc: 0.8627\n",
            "Epoch 253/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3104 - acc: 0.8579\n",
            "Epoch 254/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2755 - acc: 0.8663\n",
            "Epoch 255/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2788 - acc: 0.8647\n",
            "Epoch 256/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2932 - acc: 0.8594\n",
            "Epoch 257/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2889 - acc: 0.8631\n",
            "Epoch 258/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.3132 - acc: 0.8596\n",
            "Epoch 259/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2871 - acc: 0.8629\n",
            "Epoch 260/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2832 - acc: 0.8634\n",
            "Epoch 261/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2839 - acc: 0.8644\n",
            "Epoch 262/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2997 - acc: 0.8585\n",
            "Epoch 263/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3009 - acc: 0.8596\n",
            "Epoch 264/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2776 - acc: 0.8665\n",
            "Epoch 265/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2857 - acc: 0.8629\n",
            "Epoch 266/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2826 - acc: 0.8628\n",
            "Epoch 267/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3058 - acc: 0.8565\n",
            "Epoch 268/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2767 - acc: 0.8646\n",
            "Epoch 269/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2928 - acc: 0.8644\n",
            "Epoch 270/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2931 - acc: 0.8623\n",
            "Epoch 271/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2686 - acc: 0.8691\n",
            "Epoch 272/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2781 - acc: 0.8674\n",
            "Epoch 273/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3032 - acc: 0.8594\n",
            "Epoch 274/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2808 - acc: 0.8633\n",
            "Epoch 275/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2782 - acc: 0.8663\n",
            "Epoch 276/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2799 - acc: 0.8652\n",
            "Epoch 277/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2841 - acc: 0.8619\n",
            "Epoch 278/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2835 - acc: 0.8677\n",
            "Epoch 279/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2761 - acc: 0.8670\n",
            "Epoch 280/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2850 - acc: 0.8649\n",
            "Epoch 281/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2953 - acc: 0.8650\n",
            "Epoch 282/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2725 - acc: 0.8679\n",
            "Epoch 283/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3043 - acc: 0.8593\n",
            "Epoch 284/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2896 - acc: 0.8646\n",
            "Epoch 285/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2768 - acc: 0.8680\n",
            "Epoch 286/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2833 - acc: 0.8653\n",
            "Epoch 287/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2804 - acc: 0.8655\n",
            "Epoch 288/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2819 - acc: 0.8661\n",
            "Epoch 289/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3001 - acc: 0.8613\n",
            "Epoch 290/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2898 - acc: 0.8647\n",
            "Epoch 291/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2854 - acc: 0.8638\n",
            "Epoch 292/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2701 - acc: 0.8683\n",
            "Epoch 293/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2803 - acc: 0.8650\n",
            "Epoch 294/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2825 - acc: 0.8642\n",
            "Epoch 295/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2803 - acc: 0.8655\n",
            "Epoch 296/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3075 - acc: 0.8623\n",
            "Epoch 297/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2763 - acc: 0.8650\n",
            "Epoch 298/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2762 - acc: 0.8700\n",
            "Epoch 299/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2809 - acc: 0.8656\n",
            "Epoch 300/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2848 - acc: 0.8640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faec1dbc400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPu1wlAz_T8M",
        "colab_type": "code",
        "outputId": "6ab6d600-6126-4ba3-cc39-7e8387bb0ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 [==============================] - 19s 4ms/step - loss: 0.3293 - acc: 0.8490\n",
            "\n",
            "\n",
            "Test Loss 0.32933354961227723, Test Accuracy 0.8490151166915894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smrTorYxfben",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(15000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogZ1w12IMnBy",
        "colab_type": "code",
        "outputId": "8dc238e2-aef0-4f82-e977-9964ee7f3505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4641/4641 [==============================] - 24s 5ms/step - loss: 0.3421 - acc: 0.8446\n",
            "Epoch 2/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3258 - acc: 0.8501\n",
            "Epoch 3/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3170 - acc: 0.8491\n",
            "Epoch 4/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3408 - acc: 0.8503\n",
            "Epoch 5/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2976 - acc: 0.8562\n",
            "Epoch 6/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3238 - acc: 0.8515\n",
            "Epoch 7/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3108 - acc: 0.8550\n",
            "Epoch 8/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3124 - acc: 0.8550\n",
            "Epoch 9/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3097 - acc: 0.8570\n",
            "Epoch 10/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3248 - acc: 0.8549\n",
            "Epoch 11/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2989 - acc: 0.8595\n",
            "Epoch 12/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3025 - acc: 0.8584\n",
            "Epoch 13/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2964 - acc: 0.8571\n",
            "Epoch 14/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3224 - acc: 0.8536\n",
            "Epoch 15/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2859 - acc: 0.8614\n",
            "Epoch 16/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3170 - acc: 0.8539\n",
            "Epoch 17/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2928 - acc: 0.8613\n",
            "Epoch 18/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3096 - acc: 0.8566\n",
            "Epoch 19/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2992 - acc: 0.8606\n",
            "Epoch 20/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2870 - acc: 0.8616\n",
            "Epoch 21/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2948 - acc: 0.8619\n",
            "Epoch 22/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3028 - acc: 0.8569\n",
            "Epoch 23/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3025 - acc: 0.8609\n",
            "Epoch 24/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2870 - acc: 0.8622\n",
            "Epoch 25/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2876 - acc: 0.8624\n",
            "Epoch 26/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3078 - acc: 0.8599\n",
            "Epoch 27/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2991 - acc: 0.8603\n",
            "Epoch 28/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3108 - acc: 0.8594\n",
            "Epoch 29/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2893 - acc: 0.8639\n",
            "Epoch 30/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3040 - acc: 0.8598\n",
            "Epoch 31/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2827 - acc: 0.8650\n",
            "Epoch 32/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3039 - acc: 0.8611\n",
            "Epoch 33/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2930 - acc: 0.8620\n",
            "Epoch 34/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2849 - acc: 0.8635\n",
            "Epoch 35/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3005 - acc: 0.8635\n",
            "Epoch 36/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2858 - acc: 0.8655\n",
            "Epoch 37/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2935 - acc: 0.8638\n",
            "Epoch 38/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3090 - acc: 0.8582\n",
            "Epoch 39/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2779 - acc: 0.8663\n",
            "Epoch 40/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2825 - acc: 0.8641\n",
            "Epoch 41/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2747 - acc: 0.8675\n",
            "Epoch 42/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2919 - acc: 0.8626\n",
            "Epoch 43/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3065 - acc: 0.8605\n",
            "Epoch 44/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2730 - acc: 0.8688\n",
            "Epoch 45/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2994 - acc: 0.8617\n",
            "Epoch 46/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3086 - acc: 0.8643\n",
            "Epoch 47/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3040 - acc: 0.8622\n",
            "Epoch 48/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2840 - acc: 0.8640\n",
            "Epoch 49/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2961 - acc: 0.8634\n",
            "Epoch 50/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2824 - acc: 0.8650\n",
            "Epoch 51/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2991 - acc: 0.8631\n",
            "Epoch 52/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2946 - acc: 0.8641\n",
            "Epoch 53/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2846 - acc: 0.8677\n",
            "Epoch 54/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2860 - acc: 0.8633\n",
            "Epoch 55/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2749 - acc: 0.8678\n",
            "Epoch 56/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2825 - acc: 0.8651\n",
            "Epoch 57/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2875 - acc: 0.8655\n",
            "Epoch 58/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2839 - acc: 0.8675\n",
            "Epoch 59/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2779 - acc: 0.8701\n",
            "Epoch 60/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3068 - acc: 0.8634\n",
            "Epoch 61/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2815 - acc: 0.8691\n",
            "Epoch 62/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2837 - acc: 0.8679\n",
            "Epoch 63/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2879 - acc: 0.8638\n",
            "Epoch 64/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2789 - acc: 0.8696\n",
            "Epoch 65/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3002 - acc: 0.8625\n",
            "Epoch 66/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2699 - acc: 0.8708\n",
            "Epoch 67/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2815 - acc: 0.8696\n",
            "Epoch 68/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3119 - acc: 0.8632\n",
            "Epoch 69/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2808 - acc: 0.8681\n",
            "Epoch 70/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2732 - acc: 0.8683\n",
            "Epoch 71/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2699 - acc: 0.8697\n",
            "Epoch 72/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2809 - acc: 0.8704\n",
            "Epoch 73/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2744 - acc: 0.8697\n",
            "Epoch 74/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2829 - acc: 0.8657\n",
            "Epoch 75/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3034 - acc: 0.8658\n",
            "Epoch 76/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2720 - acc: 0.8714\n",
            "Epoch 77/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2812 - acc: 0.8681\n",
            "Epoch 78/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2798 - acc: 0.8670\n",
            "Epoch 79/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2867 - acc: 0.8667\n",
            "Epoch 80/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2799 - acc: 0.8675\n",
            "Epoch 81/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2850 - acc: 0.8686\n",
            "Epoch 82/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2928 - acc: 0.8673\n",
            "Epoch 83/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2704 - acc: 0.8713\n",
            "Epoch 84/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2868 - acc: 0.8669\n",
            "Epoch 85/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2659 - acc: 0.8731\n",
            "Epoch 86/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2740 - acc: 0.8693\n",
            "Epoch 87/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2831 - acc: 0.8668\n",
            "Epoch 88/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2827 - acc: 0.8675\n",
            "Epoch 89/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2702 - acc: 0.8706\n",
            "Epoch 90/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2766 - acc: 0.8698\n",
            "Epoch 91/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2751 - acc: 0.8718\n",
            "Epoch 92/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2817 - acc: 0.8707\n",
            "Epoch 93/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3046 - acc: 0.8675\n",
            "Epoch 94/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2907 - acc: 0.8670\n",
            "Epoch 95/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2629 - acc: 0.8733\n",
            "Epoch 96/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2737 - acc: 0.8683\n",
            "Epoch 97/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2768 - acc: 0.8705\n",
            "Epoch 98/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2772 - acc: 0.8725\n",
            "Epoch 99/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2805 - acc: 0.8696\n",
            "Epoch 100/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2711 - acc: 0.8717\n",
            "Epoch 101/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2867 - acc: 0.8689\n",
            "Epoch 102/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2631 - acc: 0.8743\n",
            "Epoch 103/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2718 - acc: 0.8725\n",
            "Epoch 104/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2766 - acc: 0.8722\n",
            "Epoch 105/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2732 - acc: 0.8725\n",
            "Epoch 106/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2655 - acc: 0.8734\n",
            "Epoch 107/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2654 - acc: 0.8729\n",
            "Epoch 108/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2811 - acc: 0.8739\n",
            "Epoch 109/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2814 - acc: 0.8696\n",
            "Epoch 110/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2748 - acc: 0.8704\n",
            "Epoch 111/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2838 - acc: 0.8721\n",
            "Epoch 112/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2637 - acc: 0.8738\n",
            "Epoch 113/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2746 - acc: 0.8708\n",
            "Epoch 114/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2776 - acc: 0.8726\n",
            "Epoch 115/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2864 - acc: 0.8708\n",
            "Epoch 116/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2609 - acc: 0.8766\n",
            "Epoch 117/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2730 - acc: 0.8730\n",
            "Epoch 118/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2584 - acc: 0.8753\n",
            "Epoch 119/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2690 - acc: 0.8732\n",
            "Epoch 120/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2578 - acc: 0.8748\n",
            "Epoch 121/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2644 - acc: 0.8742\n",
            "Epoch 122/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2665 - acc: 0.8760\n",
            "Epoch 123/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2761 - acc: 0.8711\n",
            "Epoch 124/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2928 - acc: 0.8708\n",
            "Epoch 125/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2842 - acc: 0.8695\n",
            "Epoch 126/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2908 - acc: 0.8733\n",
            "Epoch 127/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2586 - acc: 0.8764\n",
            "Epoch 128/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2832 - acc: 0.8710\n",
            "Epoch 129/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2828 - acc: 0.8725\n",
            "Epoch 130/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2650 - acc: 0.8762\n",
            "Epoch 131/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2669 - acc: 0.8744\n",
            "Epoch 132/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2585 - acc: 0.8773\n",
            "Epoch 133/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2732 - acc: 0.8788\n",
            "Epoch 134/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2662 - acc: 0.8757\n",
            "Epoch 135/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2806 - acc: 0.8723\n",
            "Epoch 136/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2726 - acc: 0.8747\n",
            "Epoch 137/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2772 - acc: 0.8711\n",
            "Epoch 138/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2720 - acc: 0.8727\n",
            "Epoch 139/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2791 - acc: 0.8713\n",
            "Epoch 140/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2880 - acc: 0.8700\n",
            "Epoch 141/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2991 - acc: 0.8689\n",
            "Epoch 142/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2689 - acc: 0.8743\n",
            "Epoch 143/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2634 - acc: 0.8791\n",
            "Epoch 144/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2853 - acc: 0.8722\n",
            "Epoch 145/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2685 - acc: 0.8769\n",
            "Epoch 146/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2583 - acc: 0.8761\n",
            "Epoch 147/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2635 - acc: 0.8771\n",
            "Epoch 148/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2559 - acc: 0.8786\n",
            "Epoch 149/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2764 - acc: 0.8726\n",
            "Epoch 150/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2716 - acc: 0.8734\n",
            "Epoch 151/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2741 - acc: 0.8729\n",
            "Epoch 152/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2751 - acc: 0.8742\n",
            "Epoch 153/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2608 - acc: 0.8758\n",
            "Epoch 154/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2817 - acc: 0.8736\n",
            "Epoch 155/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2699 - acc: 0.8751\n",
            "Epoch 156/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2949 - acc: 0.8691\n",
            "Epoch 157/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2564 - acc: 0.8791\n",
            "Epoch 158/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2749 - acc: 0.8735\n",
            "Epoch 159/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2768 - acc: 0.8734\n",
            "Epoch 160/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2631 - acc: 0.8759\n",
            "Epoch 161/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2612 - acc: 0.8758\n",
            "Epoch 162/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2590 - acc: 0.8772\n",
            "Epoch 163/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2808 - acc: 0.8737\n",
            "Epoch 164/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2616 - acc: 0.8781\n",
            "Epoch 165/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2587 - acc: 0.8751\n",
            "Epoch 166/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2501 - acc: 0.8781\n",
            "Epoch 167/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2593 - acc: 0.8791\n",
            "Epoch 168/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2905 - acc: 0.8722\n",
            "Epoch 169/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2703 - acc: 0.8746\n",
            "Epoch 170/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2859 - acc: 0.8721\n",
            "Epoch 171/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2514 - acc: 0.8800\n",
            "Epoch 172/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2654 - acc: 0.8744\n",
            "Epoch 173/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2702 - acc: 0.8765\n",
            "Epoch 174/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2571 - acc: 0.8773\n",
            "Epoch 175/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2624 - acc: 0.8758\n",
            "Epoch 176/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2592 - acc: 0.8772\n",
            "Epoch 177/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2647 - acc: 0.8788\n",
            "Epoch 178/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2663 - acc: 0.8762\n",
            "Epoch 179/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2582 - acc: 0.8797\n",
            "Epoch 180/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2691 - acc: 0.8765\n",
            "Epoch 181/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2700 - acc: 0.8741\n",
            "Epoch 182/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2636 - acc: 0.8779\n",
            "Epoch 183/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2693 - acc: 0.8752\n",
            "Epoch 184/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2702 - acc: 0.8771\n",
            "Epoch 185/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2696 - acc: 0.8747\n",
            "Epoch 186/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2703 - acc: 0.8769\n",
            "Epoch 187/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2554 - acc: 0.8788\n",
            "Epoch 188/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3015 - acc: 0.8731\n",
            "Epoch 189/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2667 - acc: 0.8795\n",
            "Epoch 190/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2829 - acc: 0.8741\n",
            "Epoch 191/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2918 - acc: 0.8732\n",
            "Epoch 192/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2539 - acc: 0.8794\n",
            "Epoch 193/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2640 - acc: 0.8794\n",
            "Epoch 194/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2561 - acc: 0.8796\n",
            "Epoch 195/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2589 - acc: 0.8800\n",
            "Epoch 196/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2655 - acc: 0.8771\n",
            "Epoch 197/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2527 - acc: 0.8788\n",
            "Epoch 198/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2508 - acc: 0.8807\n",
            "Epoch 199/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2637 - acc: 0.8770\n",
            "Epoch 200/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2641 - acc: 0.8778\n",
            "Epoch 201/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2624 - acc: 0.8779\n",
            "Epoch 202/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2561 - acc: 0.8792\n",
            "Epoch 203/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2844 - acc: 0.8725\n",
            "Epoch 204/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2493 - acc: 0.8813\n",
            "Epoch 205/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2700 - acc: 0.8765\n",
            "Epoch 206/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2624 - acc: 0.8795\n",
            "Epoch 207/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2705 - acc: 0.8759\n",
            "Epoch 208/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2674 - acc: 0.8775\n",
            "Epoch 209/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2769 - acc: 0.8755\n",
            "Epoch 210/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2718 - acc: 0.8766\n",
            "Epoch 211/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2448 - acc: 0.8822\n",
            "Epoch 212/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2729 - acc: 0.8748\n",
            "Epoch 213/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2715 - acc: 0.8797\n",
            "Epoch 214/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2535 - acc: 0.8817\n",
            "Epoch 215/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2619 - acc: 0.8775\n",
            "Epoch 216/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2744 - acc: 0.8769\n",
            "Epoch 217/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2673 - acc: 0.8776\n",
            "Epoch 218/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2693 - acc: 0.8770\n",
            "Epoch 219/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2518 - acc: 0.8808\n",
            "Epoch 220/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2530 - acc: 0.8800\n",
            "Epoch 221/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2654 - acc: 0.8775\n",
            "Epoch 222/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2609 - acc: 0.8819\n",
            "Epoch 223/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2722 - acc: 0.8767\n",
            "Epoch 224/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2784 - acc: 0.8755\n",
            "Epoch 225/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2524 - acc: 0.8829\n",
            "Epoch 226/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2544 - acc: 0.8799\n",
            "Epoch 227/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2613 - acc: 0.8784\n",
            "Epoch 228/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2569 - acc: 0.8793\n",
            "Epoch 229/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2482 - acc: 0.8805\n",
            "Epoch 230/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2527 - acc: 0.8803\n",
            "Epoch 231/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2639 - acc: 0.8775\n",
            "Epoch 232/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2701 - acc: 0.8772\n",
            "Epoch 233/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2484 - acc: 0.8813\n",
            "Epoch 234/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2554 - acc: 0.8791\n",
            "Epoch 235/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2570 - acc: 0.8795\n",
            "Epoch 236/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2598 - acc: 0.8807\n",
            "Epoch 237/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2509 - acc: 0.8823\n",
            "Epoch 238/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2597 - acc: 0.8802\n",
            "Epoch 239/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2496 - acc: 0.8816\n",
            "Epoch 240/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2573 - acc: 0.8811\n",
            "Epoch 241/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2435 - acc: 0.8850\n",
            "Epoch 242/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2529 - acc: 0.8800\n",
            "Epoch 243/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2737 - acc: 0.8774\n",
            "Epoch 244/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2716 - acc: 0.8791\n",
            "Epoch 245/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2435 - acc: 0.8839\n",
            "Epoch 246/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2517 - acc: 0.8797\n",
            "Epoch 247/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2500 - acc: 0.8824\n",
            "Epoch 248/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2605 - acc: 0.8811\n",
            "Epoch 249/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2435 - acc: 0.8829\n",
            "Epoch 250/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2869 - acc: 0.8734\n",
            "Epoch 251/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2726 - acc: 0.8782\n",
            "Epoch 252/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2538 - acc: 0.8829\n",
            "Epoch 253/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2488 - acc: 0.8819\n",
            "Epoch 254/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2496 - acc: 0.8810\n",
            "Epoch 255/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2700 - acc: 0.8804\n",
            "Epoch 256/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2506 - acc: 0.8850\n",
            "Epoch 257/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2370 - acc: 0.8851\n",
            "Epoch 258/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2488 - acc: 0.8830\n",
            "Epoch 259/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2741 - acc: 0.8802\n",
            "Epoch 260/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2708 - acc: 0.8800\n",
            "Epoch 261/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2757 - acc: 0.8800\n",
            "Epoch 262/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2412 - acc: 0.8863\n",
            "Epoch 263/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2600 - acc: 0.8838\n",
            "Epoch 264/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2485 - acc: 0.8852\n",
            "Epoch 265/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2618 - acc: 0.8826\n",
            "Epoch 266/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2668 - acc: 0.8819\n",
            "Epoch 267/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2392 - acc: 0.8863\n",
            "Epoch 268/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2475 - acc: 0.8833\n",
            "Epoch 269/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2439 - acc: 0.8850\n",
            "Epoch 270/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2682 - acc: 0.8794\n",
            "Epoch 271/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2602 - acc: 0.8805\n",
            "Epoch 272/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2795 - acc: 0.8777\n",
            "Epoch 273/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2458 - acc: 0.8851\n",
            "Epoch 274/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2512 - acc: 0.8832\n",
            "Epoch 275/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2518 - acc: 0.8835\n",
            "Epoch 276/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2572 - acc: 0.8813\n",
            "Epoch 277/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2442 - acc: 0.8840\n",
            "Epoch 278/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2660 - acc: 0.8810\n",
            "Epoch 279/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2772 - acc: 0.8843\n",
            "Epoch 280/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2470 - acc: 0.8838\n",
            "Epoch 281/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2605 - acc: 0.8822\n",
            "Epoch 282/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2424 - acc: 0.8832\n",
            "Epoch 283/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2568 - acc: 0.8830\n",
            "Epoch 284/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2429 - acc: 0.8843\n",
            "Epoch 285/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2656 - acc: 0.8794\n",
            "Epoch 286/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2516 - acc: 0.8855\n",
            "Epoch 287/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2653 - acc: 0.8820\n",
            "Epoch 288/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2476 - acc: 0.8810\n",
            "Epoch 289/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2524 - acc: 0.8845\n",
            "Epoch 290/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2527 - acc: 0.8834\n",
            "Epoch 291/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2414 - acc: 0.8855\n",
            "Epoch 292/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2757 - acc: 0.8798\n",
            "Epoch 293/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2418 - acc: 0.8855\n",
            "Epoch 294/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2572 - acc: 0.8825\n",
            "Epoch 295/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2511 - acc: 0.8848\n",
            "Epoch 296/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2508 - acc: 0.8843\n",
            "Epoch 297/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2425 - acc: 0.8858\n",
            "Epoch 298/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2667 - acc: 0.8813\n",
            "Epoch 299/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2353 - acc: 0.8882\n",
            "Epoch 300/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2645 - acc: 0.8808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faebbe86940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-vXAAD-Mpo7",
        "colab_type": "code",
        "outputId": "5616061a-1da4-4c80-e475-575d52243cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 [==============================] - 18s 4ms/step - loss: 0.2420 - acc: 0.8822\n",
            "\n",
            "\n",
            "Test Loss 0.2420369508353826, Test Accuracy 0.8822464346885681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPrMGqZM59gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(15000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gclkwjx5-Dq",
        "colab_type": "code",
        "outputId": "61c5f40b-5847-4acb-a693-29ca6d58e48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "4641/4641 [==============================] - 24s 5ms/step - loss: 0.2970 - acc: 0.8682\n",
            "Epoch 2/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2638 - acc: 0.8781\n",
            "Epoch 3/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3210 - acc: 0.8683\n",
            "Epoch 4/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2802 - acc: 0.8725\n",
            "Epoch 5/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2595 - acc: 0.8754\n",
            "Epoch 6/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2999 - acc: 0.8714\n",
            "Epoch 7/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2579 - acc: 0.8804\n",
            "Epoch 8/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2579 - acc: 0.8748\n",
            "Epoch 9/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2795 - acc: 0.8770\n",
            "Epoch 10/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2613 - acc: 0.8800\n",
            "Epoch 11/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2625 - acc: 0.8787\n",
            "Epoch 12/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2686 - acc: 0.8773\n",
            "Epoch 13/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2755 - acc: 0.8793\n",
            "Epoch 14/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2661 - acc: 0.8766\n",
            "Epoch 15/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2598 - acc: 0.8778\n",
            "Epoch 16/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2646 - acc: 0.8786\n",
            "Epoch 17/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2618 - acc: 0.8779\n",
            "Epoch 18/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2747 - acc: 0.8777\n",
            "Epoch 19/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2488 - acc: 0.8827\n",
            "Epoch 20/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2787 - acc: 0.8757\n",
            "Epoch 21/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2551 - acc: 0.8779\n",
            "Epoch 22/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2778 - acc: 0.8780\n",
            "Epoch 23/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2572 - acc: 0.8796\n",
            "Epoch 24/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2775 - acc: 0.8775\n",
            "Epoch 25/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2580 - acc: 0.8830\n",
            "Epoch 26/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2467 - acc: 0.8843\n",
            "Epoch 27/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2531 - acc: 0.8803\n",
            "Epoch 28/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2537 - acc: 0.8815\n",
            "Epoch 29/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2658 - acc: 0.8801\n",
            "Epoch 30/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2637 - acc: 0.8810\n",
            "Epoch 31/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2562 - acc: 0.8812\n",
            "Epoch 32/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2471 - acc: 0.8821\n",
            "Epoch 33/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2773 - acc: 0.8775\n",
            "Epoch 34/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2666 - acc: 0.8800\n",
            "Epoch 35/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2557 - acc: 0.8818\n",
            "Epoch 36/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2464 - acc: 0.8838\n",
            "Epoch 37/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2710 - acc: 0.8770\n",
            "Epoch 38/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2582 - acc: 0.8803\n",
            "Epoch 39/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2594 - acc: 0.8785\n",
            "Epoch 40/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2520 - acc: 0.8823\n",
            "Epoch 41/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2521 - acc: 0.8832\n",
            "Epoch 42/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2577 - acc: 0.8807\n",
            "Epoch 43/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2426 - acc: 0.8822\n",
            "Epoch 44/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2571 - acc: 0.8794\n",
            "Epoch 45/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2524 - acc: 0.8813\n",
            "Epoch 46/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2621 - acc: 0.8795\n",
            "Epoch 47/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2528 - acc: 0.8803\n",
            "Epoch 48/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2358 - acc: 0.8865\n",
            "Epoch 49/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2443 - acc: 0.8826\n",
            "Epoch 50/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2528 - acc: 0.8816\n",
            "Epoch 51/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2438 - acc: 0.8832\n",
            "Epoch 52/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2567 - acc: 0.8812\n",
            "Epoch 53/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2619 - acc: 0.8791\n",
            "Epoch 54/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2719 - acc: 0.8781\n",
            "Epoch 55/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2355 - acc: 0.8863\n",
            "Epoch 56/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2601 - acc: 0.8820\n",
            "Epoch 57/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2498 - acc: 0.8835\n",
            "Epoch 58/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2552 - acc: 0.8832\n",
            "Epoch 59/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2710 - acc: 0.8816\n",
            "Epoch 60/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2561 - acc: 0.8811\n",
            "Epoch 61/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2474 - acc: 0.8837\n",
            "Epoch 62/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2516 - acc: 0.8838\n",
            "Epoch 63/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2601 - acc: 0.8822\n",
            "Epoch 64/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2467 - acc: 0.8850\n",
            "Epoch 65/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2415 - acc: 0.8847\n",
            "Epoch 66/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2790 - acc: 0.8808\n",
            "Epoch 67/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2582 - acc: 0.8816\n",
            "Epoch 68/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2472 - acc: 0.8851\n",
            "Epoch 69/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2465 - acc: 0.8831\n",
            "Epoch 70/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2472 - acc: 0.8857\n",
            "Epoch 71/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2496 - acc: 0.8835\n",
            "Epoch 72/200\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2536 - acc: 0.8837\n",
            "Epoch 73/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2421 - acc: 0.8844\n",
            "Epoch 74/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2508 - acc: 0.8851\n",
            "Epoch 75/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2518 - acc: 0.8837\n",
            "Epoch 76/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2451 - acc: 0.8861\n",
            "Epoch 77/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2611 - acc: 0.8819\n",
            "Epoch 78/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2651 - acc: 0.8824\n",
            "Epoch 79/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2529 - acc: 0.8845\n",
            "Epoch 80/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2437 - acc: 0.8850\n",
            "Epoch 81/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2364 - acc: 0.8883\n",
            "Epoch 82/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2641 - acc: 0.8792\n",
            "Epoch 83/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2575 - acc: 0.8824\n",
            "Epoch 84/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2518 - acc: 0.8847\n",
            "Epoch 85/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2463 - acc: 0.8833\n",
            "Epoch 86/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2636 - acc: 0.8819\n",
            "Epoch 87/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2258 - acc: 0.8896\n",
            "Epoch 88/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2469 - acc: 0.8837\n",
            "Epoch 89/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2428 - acc: 0.8862\n",
            "Epoch 90/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2424 - acc: 0.8874\n",
            "Epoch 91/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2370 - acc: 0.8874\n",
            "Epoch 92/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2650 - acc: 0.8814\n",
            "Epoch 93/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2375 - acc: 0.8872\n",
            "Epoch 94/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2467 - acc: 0.8847\n",
            "Epoch 95/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2455 - acc: 0.8864\n",
            "Epoch 96/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2448 - acc: 0.8844\n",
            "Epoch 97/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2337 - acc: 0.8879\n",
            "Epoch 98/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2485 - acc: 0.8839\n",
            "Epoch 99/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2402 - acc: 0.8855\n",
            "Epoch 100/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2460 - acc: 0.8858\n",
            "Epoch 101/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2498 - acc: 0.8838\n",
            "Epoch 102/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2562 - acc: 0.8851\n",
            "Epoch 103/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2681 - acc: 0.8823\n",
            "Epoch 104/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2542 - acc: 0.8842\n",
            "Epoch 105/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2431 - acc: 0.8864\n",
            "Epoch 106/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2569 - acc: 0.8793\n",
            "Epoch 107/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2569 - acc: 0.8843\n",
            "Epoch 108/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2522 - acc: 0.8853\n",
            "Epoch 109/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2341 - acc: 0.8873\n",
            "Epoch 110/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2407 - acc: 0.8840\n",
            "Epoch 111/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2506 - acc: 0.8819\n",
            "Epoch 112/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2349 - acc: 0.8870\n",
            "Epoch 113/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2568 - acc: 0.8836\n",
            "Epoch 114/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2552 - acc: 0.8847\n",
            "Epoch 115/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2521 - acc: 0.8844\n",
            "Epoch 116/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2367 - acc: 0.8856\n",
            "Epoch 117/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2534 - acc: 0.8849\n",
            "Epoch 118/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2397 - acc: 0.8866\n",
            "Epoch 119/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2409 - acc: 0.8844\n",
            "Epoch 120/200\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2467 - acc: 0.8850\n",
            "Epoch 121/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2469 - acc: 0.8854\n",
            "Epoch 122/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2497 - acc: 0.8855\n",
            "Epoch 123/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2504 - acc: 0.8833\n",
            "Epoch 124/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2592 - acc: 0.8819\n",
            "Epoch 125/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2419 - acc: 0.8875\n",
            "Epoch 126/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2321 - acc: 0.8897\n",
            "Epoch 127/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2623 - acc: 0.8848\n",
            "Epoch 128/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2361 - acc: 0.8887\n",
            "Epoch 129/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2530 - acc: 0.8828\n",
            "Epoch 130/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2338 - acc: 0.8880\n",
            "Epoch 131/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2341 - acc: 0.8888\n",
            "Epoch 132/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2449 - acc: 0.8857\n",
            "Epoch 133/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2385 - acc: 0.8867\n",
            "Epoch 134/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2549 - acc: 0.8835\n",
            "Epoch 135/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2314 - acc: 0.8908\n",
            "Epoch 136/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2524 - acc: 0.8847\n",
            "Epoch 137/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2307 - acc: 0.8885\n",
            "Epoch 138/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2500 - acc: 0.8874\n",
            "Epoch 139/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2763 - acc: 0.8799\n",
            "Epoch 140/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2243 - acc: 0.8907\n",
            "Epoch 141/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2525 - acc: 0.8838\n",
            "Epoch 142/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2534 - acc: 0.8853\n",
            "Epoch 143/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2389 - acc: 0.8882\n",
            "Epoch 144/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2547 - acc: 0.8881\n",
            "Epoch 145/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2331 - acc: 0.8895\n",
            "Epoch 146/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2826 - acc: 0.8834\n",
            "Epoch 147/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2382 - acc: 0.8881\n",
            "Epoch 148/200\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2434 - acc: 0.8884\n",
            "Epoch 149/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2508 - acc: 0.8872\n",
            "Epoch 150/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2420 - acc: 0.8869\n",
            "Epoch 151/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2484 - acc: 0.8874\n",
            "Epoch 152/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2471 - acc: 0.8874\n",
            "Epoch 153/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2288 - acc: 0.8902\n",
            "Epoch 154/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2621 - acc: 0.8846\n",
            "Epoch 155/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2407 - acc: 0.8879\n",
            "Epoch 156/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2421 - acc: 0.8872\n",
            "Epoch 157/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2658 - acc: 0.8846\n",
            "Epoch 158/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2364 - acc: 0.8903\n",
            "Epoch 159/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2566 - acc: 0.8839\n",
            "Epoch 160/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2373 - acc: 0.8871\n",
            "Epoch 161/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2286 - acc: 0.8884\n",
            "Epoch 162/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2391 - acc: 0.8855\n",
            "Epoch 163/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2638 - acc: 0.8833\n",
            "Epoch 164/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2479 - acc: 0.8902\n",
            "Epoch 165/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2379 - acc: 0.8873\n",
            "Epoch 166/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2362 - acc: 0.8894\n",
            "Epoch 167/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2329 - acc: 0.8891\n",
            "Epoch 168/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2325 - acc: 0.8885\n",
            "Epoch 169/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2402 - acc: 0.8870\n",
            "Epoch 170/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2496 - acc: 0.8875\n",
            "Epoch 171/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2354 - acc: 0.8865\n",
            "Epoch 172/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2347 - acc: 0.8879\n",
            "Epoch 173/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2312 - acc: 0.8888\n",
            "Epoch 174/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2513 - acc: 0.8863\n",
            "Epoch 175/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2410 - acc: 0.8877\n",
            "Epoch 176/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2232 - acc: 0.8913\n",
            "Epoch 177/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2486 - acc: 0.8876\n",
            "Epoch 178/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2308 - acc: 0.8894\n",
            "Epoch 179/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2581 - acc: 0.8840\n",
            "Epoch 180/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2428 - acc: 0.8907\n",
            "Epoch 181/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2367 - acc: 0.8889\n",
            "Epoch 182/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2384 - acc: 0.8890\n",
            "Epoch 183/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2437 - acc: 0.8861\n",
            "Epoch 184/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2308 - acc: 0.8889\n",
            "Epoch 185/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2414 - acc: 0.8863\n",
            "Epoch 186/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2496 - acc: 0.8866\n",
            "Epoch 187/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2282 - acc: 0.8915\n",
            "Epoch 188/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2448 - acc: 0.8885\n",
            "Epoch 189/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2247 - acc: 0.8922\n",
            "Epoch 190/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2392 - acc: 0.8894\n",
            "Epoch 191/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2392 - acc: 0.8890\n",
            "Epoch 192/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2379 - acc: 0.8880\n",
            "Epoch 193/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2383 - acc: 0.8884\n",
            "Epoch 194/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2379 - acc: 0.8885\n",
            "Epoch 195/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2514 - acc: 0.8859\n",
            "Epoch 196/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2413 - acc: 0.8870\n",
            "Epoch 197/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2336 - acc: 0.8876\n",
            "Epoch 198/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2394 - acc: 0.8867\n",
            "Epoch 199/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2432 - acc: 0.8875\n",
            "Epoch 200/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2456 - acc: 0.8879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faebbe86240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLh1HfRQ5-jC",
        "colab_type": "code",
        "outputId": "2c851602-71bf-44d1-cc6f-5692d6624daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 [==============================] - 18s 4ms/step - loss: 0.2648 - acc: 0.8828\n",
            "\n",
            "\n",
            "Test Loss 0.26475580574369434, Test Accuracy 0.8828498721122742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQL5vZzw6IEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(15000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYSloq56Jrc",
        "colab_type": "code",
        "outputId": "6862496f-9eb2-4935-e187-ac39994903e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "4641/4641 [==============================] - 24s 5ms/step - loss: 0.2641 - acc: 0.8803\n",
            "Epoch 2/200\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2480 - acc: 0.8835\n",
            "Epoch 3/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2653 - acc: 0.8791\n",
            "Epoch 4/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2718 - acc: 0.8797\n",
            "Epoch 5/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2381 - acc: 0.8847\n",
            "Epoch 6/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2635 - acc: 0.8817\n",
            "Epoch 7/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2317 - acc: 0.8882\n",
            "Epoch 8/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2489 - acc: 0.8846\n",
            "Epoch 9/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2609 - acc: 0.8851\n",
            "Epoch 10/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2336 - acc: 0.8873\n",
            "Epoch 11/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2502 - acc: 0.8838\n",
            "Epoch 12/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2604 - acc: 0.8856\n",
            "Epoch 13/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2679 - acc: 0.8849\n",
            "Epoch 14/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2537 - acc: 0.8865\n",
            "Epoch 15/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2476 - acc: 0.8863\n",
            "Epoch 16/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2588 - acc: 0.8840\n",
            "Epoch 17/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2397 - acc: 0.8853\n",
            "Epoch 18/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2391 - acc: 0.8890\n",
            "Epoch 19/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2587 - acc: 0.8837\n",
            "Epoch 20/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2368 - acc: 0.8860\n",
            "Epoch 21/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2466 - acc: 0.8864\n",
            "Epoch 22/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2475 - acc: 0.8874\n",
            "Epoch 23/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2530 - acc: 0.8848\n",
            "Epoch 24/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2397 - acc: 0.8885\n",
            "Epoch 25/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2624 - acc: 0.8825\n",
            "Epoch 26/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2353 - acc: 0.8882\n",
            "Epoch 27/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2504 - acc: 0.8859\n",
            "Epoch 28/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2309 - acc: 0.8895\n",
            "Epoch 29/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2392 - acc: 0.8872\n",
            "Epoch 30/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2513 - acc: 0.8855\n",
            "Epoch 31/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2329 - acc: 0.8925\n",
            "Epoch 32/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2450 - acc: 0.8866\n",
            "Epoch 33/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2580 - acc: 0.8847\n",
            "Epoch 34/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2392 - acc: 0.8895\n",
            "Epoch 35/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2470 - acc: 0.8873\n",
            "Epoch 36/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2334 - acc: 0.8900\n",
            "Epoch 37/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2367 - acc: 0.8877\n",
            "Epoch 38/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2541 - acc: 0.8860\n",
            "Epoch 39/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2381 - acc: 0.8900\n",
            "Epoch 40/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2265 - acc: 0.8904\n",
            "Epoch 41/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2497 - acc: 0.8857\n",
            "Epoch 42/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2349 - acc: 0.8892\n",
            "Epoch 43/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2492 - acc: 0.8873\n",
            "Epoch 44/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2273 - acc: 0.8910\n",
            "Epoch 45/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2412 - acc: 0.8891\n",
            "Epoch 46/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2331 - acc: 0.8881\n",
            "Epoch 47/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2519 - acc: 0.8877\n",
            "Epoch 48/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2506 - acc: 0.8872\n",
            "Epoch 49/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2545 - acc: 0.8869\n",
            "Epoch 50/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2371 - acc: 0.8887\n",
            "Epoch 51/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2461 - acc: 0.8886\n",
            "Epoch 52/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2397 - acc: 0.8874\n",
            "Epoch 53/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2450 - acc: 0.8883\n",
            "Epoch 54/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2509 - acc: 0.8862\n",
            "Epoch 55/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2223 - acc: 0.8913\n",
            "Epoch 56/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2464 - acc: 0.8891\n",
            "Epoch 57/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2469 - acc: 0.8894\n",
            "Epoch 58/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2398 - acc: 0.8897\n",
            "Epoch 59/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2276 - acc: 0.8913\n",
            "Epoch 60/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2546 - acc: 0.8868\n",
            "Epoch 61/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2283 - acc: 0.8920\n",
            "Epoch 62/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2400 - acc: 0.8888\n",
            "Epoch 63/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2392 - acc: 0.8884\n",
            "Epoch 64/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2376 - acc: 0.8889\n",
            "Epoch 65/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2264 - acc: 0.8923\n",
            "Epoch 66/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2417 - acc: 0.8875\n",
            "Epoch 67/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2322 - acc: 0.8893\n",
            "Epoch 68/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2260 - acc: 0.8914\n",
            "Epoch 69/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2416 - acc: 0.8890\n",
            "Epoch 70/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2208 - acc: 0.8935\n",
            "Epoch 71/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2536 - acc: 0.8860\n",
            "Epoch 72/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2214 - acc: 0.8938\n",
            "Epoch 73/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2537 - acc: 0.8864\n",
            "Epoch 74/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2400 - acc: 0.8878\n",
            "Epoch 75/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2219 - acc: 0.8931\n",
            "Epoch 76/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2319 - acc: 0.8899\n",
            "Epoch 77/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2710 - acc: 0.8852\n",
            "Epoch 78/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2595 - acc: 0.8872\n",
            "Epoch 79/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2320 - acc: 0.8908\n",
            "Epoch 80/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2321 - acc: 0.8916\n",
            "Epoch 81/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2346 - acc: 0.8910\n",
            "Epoch 82/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2471 - acc: 0.8897\n",
            "Epoch 83/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2439 - acc: 0.8908\n",
            "Epoch 84/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2478 - acc: 0.8896\n",
            "Epoch 85/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2351 - acc: 0.8905\n",
            "Epoch 86/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2256 - acc: 0.8938\n",
            "Epoch 87/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2368 - acc: 0.8911\n",
            "Epoch 88/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2273 - acc: 0.8925\n",
            "Epoch 89/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2273 - acc: 0.8916\n",
            "Epoch 90/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2360 - acc: 0.8914\n",
            "Epoch 91/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2260 - acc: 0.8910\n",
            "Epoch 92/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2212 - acc: 0.8944\n",
            "Epoch 93/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2391 - acc: 0.8894\n",
            "Epoch 94/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2420 - acc: 0.8917\n",
            "Epoch 95/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2354 - acc: 0.8920\n",
            "Epoch 96/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2314 - acc: 0.8930\n",
            "Epoch 97/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2473 - acc: 0.8900\n",
            "Epoch 98/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2429 - acc: 0.8899\n",
            "Epoch 99/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2222 - acc: 0.8944\n",
            "Epoch 100/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2419 - acc: 0.8917\n",
            "Epoch 101/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2594 - acc: 0.8900\n",
            "Epoch 102/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2308 - acc: 0.8938\n",
            "Epoch 103/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2376 - acc: 0.8893\n",
            "Epoch 104/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2267 - acc: 0.8944\n",
            "Epoch 105/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2235 - acc: 0.8953\n",
            "Epoch 106/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2231 - acc: 0.8944\n",
            "Epoch 107/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2327 - acc: 0.8922\n",
            "Epoch 108/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2527 - acc: 0.8905\n",
            "Epoch 109/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2364 - acc: 0.8909\n",
            "Epoch 110/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2420 - acc: 0.8911\n",
            "Epoch 111/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2243 - acc: 0.8918\n",
            "Epoch 112/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2356 - acc: 0.8904\n",
            "Epoch 113/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2210 - acc: 0.8932\n",
            "Epoch 114/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2217 - acc: 0.8922\n",
            "Epoch 115/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2515 - acc: 0.8867\n",
            "Epoch 116/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2232 - acc: 0.8941\n",
            "Epoch 117/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2280 - acc: 0.8913\n",
            "Epoch 118/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2387 - acc: 0.8925\n",
            "Epoch 119/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2303 - acc: 0.8925\n",
            "Epoch 120/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2237 - acc: 0.8941\n",
            "Epoch 121/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2234 - acc: 0.8950\n",
            "Epoch 122/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2346 - acc: 0.8924\n",
            "Epoch 123/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2232 - acc: 0.8951\n",
            "Epoch 124/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2247 - acc: 0.8922\n",
            "Epoch 125/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2357 - acc: 0.8910\n",
            "Epoch 126/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2383 - acc: 0.8912\n",
            "Epoch 127/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2168 - acc: 0.8938\n",
            "Epoch 128/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2485 - acc: 0.8880\n",
            "Epoch 129/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2220 - acc: 0.8955\n",
            "Epoch 130/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2388 - acc: 0.8919\n",
            "Epoch 131/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2367 - acc: 0.8909\n",
            "Epoch 132/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2261 - acc: 0.8947\n",
            "Epoch 133/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2255 - acc: 0.8948\n",
            "Epoch 134/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2316 - acc: 0.8918\n",
            "Epoch 135/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2308 - acc: 0.8948\n",
            "Epoch 136/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2357 - acc: 0.8925\n",
            "Epoch 137/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2192 - acc: 0.8957\n",
            "Epoch 138/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2400 - acc: 0.8909\n",
            "Epoch 139/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2513 - acc: 0.8896\n",
            "Epoch 140/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2249 - acc: 0.8950\n",
            "Epoch 141/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2461 - acc: 0.8897\n",
            "Epoch 142/200\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2262 - acc: 0.8950\n",
            "Epoch 143/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2349 - acc: 0.8917\n",
            "Epoch 144/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2350 - acc: 0.8935\n",
            "Epoch 145/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2230 - acc: 0.8948\n",
            "Epoch 146/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2553 - acc: 0.8918\n",
            "Epoch 147/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2368 - acc: 0.8924\n",
            "Epoch 148/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2261 - acc: 0.8948\n",
            "Epoch 149/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2351 - acc: 0.8915\n",
            "Epoch 150/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2210 - acc: 0.8944\n",
            "Epoch 151/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2319 - acc: 0.8938\n",
            "Epoch 152/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2463 - acc: 0.8884\n",
            "Epoch 153/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2387 - acc: 0.8907\n",
            "Epoch 154/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2233 - acc: 0.8944\n",
            "Epoch 155/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2427 - acc: 0.8901\n",
            "Epoch 156/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2121 - acc: 0.8959\n",
            "Epoch 157/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2198 - acc: 0.8951\n",
            "Epoch 158/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2453 - acc: 0.8895\n",
            "Epoch 159/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2258 - acc: 0.8942\n",
            "Epoch 160/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2204 - acc: 0.8957\n",
            "Epoch 161/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2232 - acc: 0.8944\n",
            "Epoch 162/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2382 - acc: 0.8904\n",
            "Epoch 163/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2180 - acc: 0.8959\n",
            "Epoch 164/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2330 - acc: 0.8934\n",
            "Epoch 165/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2313 - acc: 0.8927\n",
            "Epoch 166/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2271 - acc: 0.8947\n",
            "Epoch 167/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2142 - acc: 0.8966\n",
            "Epoch 168/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2262 - acc: 0.8932\n",
            "Epoch 169/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2268 - acc: 0.8933\n",
            "Epoch 170/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2244 - acc: 0.8955\n",
            "Epoch 171/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2249 - acc: 0.8959\n",
            "Epoch 172/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2200 - acc: 0.8975\n",
            "Epoch 173/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2386 - acc: 0.8930\n",
            "Epoch 174/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2509 - acc: 0.8916\n",
            "Epoch 175/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2344 - acc: 0.8910\n",
            "Epoch 176/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2474 - acc: 0.8941\n",
            "Epoch 177/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2145 - acc: 0.8961\n",
            "Epoch 178/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2339 - acc: 0.8948\n",
            "Epoch 179/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2270 - acc: 0.8934\n",
            "Epoch 180/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2227 - acc: 0.8941\n",
            "Epoch 181/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2277 - acc: 0.8935\n",
            "Epoch 182/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2232 - acc: 0.8970\n",
            "Epoch 183/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2186 - acc: 0.8957\n",
            "Epoch 184/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2372 - acc: 0.8932\n",
            "Epoch 185/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2184 - acc: 0.8949\n",
            "Epoch 186/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2240 - acc: 0.8938\n",
            "Epoch 187/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2240 - acc: 0.8953\n",
            "Epoch 188/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2346 - acc: 0.8935\n",
            "Epoch 189/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2229 - acc: 0.8961\n",
            "Epoch 190/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2375 - acc: 0.8913\n",
            "Epoch 191/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2177 - acc: 0.8968\n",
            "Epoch 192/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2170 - acc: 0.8957\n",
            "Epoch 193/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2342 - acc: 0.8903\n",
            "Epoch 194/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2243 - acc: 0.8950\n",
            "Epoch 195/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2334 - acc: 0.8916\n",
            "Epoch 196/200\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2110 - acc: 0.8983\n",
            "Epoch 197/200\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2336 - acc: 0.8921\n",
            "Epoch 198/200\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2125 - acc: 0.8975\n",
            "Epoch 199/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2333 - acc: 0.8928\n",
            "Epoch 200/200\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2310 - acc: 0.8940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faeb8d15e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB0uF3V36LrS",
        "colab_type": "code",
        "outputId": "dc020476-d8c7-440f-eacb-893cd59eb1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 [==============================] - 19s 4ms/step - loss: 0.2402 - acc: 0.8894\n",
            "\n",
            "\n",
            "Test Loss 0.24016748056134873, Test Accuracy 0.8893582224845886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMLmKpaZmD-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(15000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCVKjT-tmKsG",
        "colab_type": "code",
        "outputId": "383c0b96-34d3-4115-f567-84ce4fc8c2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4641/4641 [==============================] - 25s 5ms/step - loss: 0.2451 - acc: 0.8882\n",
            "Epoch 2/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2454 - acc: 0.8888\n",
            "Epoch 3/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2547 - acc: 0.8882\n",
            "Epoch 4/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2370 - acc: 0.8908\n",
            "Epoch 5/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2754 - acc: 0.8878\n",
            "Epoch 6/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2352 - acc: 0.8917\n",
            "Epoch 7/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2536 - acc: 0.8887\n",
            "Epoch 8/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2279 - acc: 0.8908\n",
            "Epoch 9/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2286 - acc: 0.8939\n",
            "Epoch 10/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2400 - acc: 0.8897\n",
            "Epoch 11/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2335 - acc: 0.8914\n",
            "Epoch 12/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2328 - acc: 0.8936\n",
            "Epoch 13/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2349 - acc: 0.8894\n",
            "Epoch 14/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2342 - acc: 0.8920\n",
            "Epoch 15/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2306 - acc: 0.8916\n",
            "Epoch 16/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2207 - acc: 0.8933\n",
            "Epoch 17/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2331 - acc: 0.8911\n",
            "Epoch 18/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2287 - acc: 0.8944\n",
            "Epoch 19/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2315 - acc: 0.8943\n",
            "Epoch 20/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2309 - acc: 0.8916\n",
            "Epoch 21/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2379 - acc: 0.8930\n",
            "Epoch 22/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2216 - acc: 0.8942\n",
            "Epoch 23/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2372 - acc: 0.8930\n",
            "Epoch 24/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2346 - acc: 0.8925\n",
            "Epoch 25/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2133 - acc: 0.8959\n",
            "Epoch 26/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2584 - acc: 0.8907\n",
            "Epoch 27/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2266 - acc: 0.8954\n",
            "Epoch 28/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2340 - acc: 0.8933\n",
            "Epoch 29/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2290 - acc: 0.8962\n",
            "Epoch 30/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2295 - acc: 0.8959\n",
            "Epoch 31/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2305 - acc: 0.8937\n",
            "Epoch 32/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2238 - acc: 0.8953\n",
            "Epoch 33/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2451 - acc: 0.8910\n",
            "Epoch 34/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2362 - acc: 0.8935\n",
            "Epoch 35/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2179 - acc: 0.8948\n",
            "Epoch 36/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2492 - acc: 0.8909\n",
            "Epoch 37/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2353 - acc: 0.8941\n",
            "Epoch 38/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2287 - acc: 0.8952\n",
            "Epoch 39/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2287 - acc: 0.8939\n",
            "Epoch 40/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2066 - acc: 0.8993\n",
            "Epoch 41/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2405 - acc: 0.8917\n",
            "Epoch 42/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2342 - acc: 0.8951\n",
            "Epoch 43/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2287 - acc: 0.8947\n",
            "Epoch 44/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2319 - acc: 0.8958\n",
            "Epoch 45/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2526 - acc: 0.8915\n",
            "Epoch 46/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2263 - acc: 0.8952\n",
            "Epoch 47/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2206 - acc: 0.8972\n",
            "Epoch 48/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2341 - acc: 0.8923\n",
            "Epoch 49/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2437 - acc: 0.8925\n",
            "Epoch 50/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2025 - acc: 0.9001\n",
            "Epoch 51/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2654 - acc: 0.8888\n",
            "Epoch 52/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2235 - acc: 0.8962\n",
            "Epoch 53/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2297 - acc: 0.8947\n",
            "Epoch 54/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2085 - acc: 0.8996\n",
            "Epoch 55/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2254 - acc: 0.8953\n",
            "Epoch 56/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2293 - acc: 0.8941\n",
            "Epoch 57/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2432 - acc: 0.8942\n",
            "Epoch 58/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2188 - acc: 0.8988\n",
            "Epoch 59/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2440 - acc: 0.8905\n",
            "Epoch 60/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2166 - acc: 0.8968\n",
            "Epoch 61/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2420 - acc: 0.8925\n",
            "Epoch 62/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2283 - acc: 0.8957\n",
            "Epoch 63/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2334 - acc: 0.8954\n",
            "Epoch 64/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2487 - acc: 0.8915\n",
            "Epoch 65/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2230 - acc: 0.8972\n",
            "Epoch 66/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2308 - acc: 0.8950\n",
            "Epoch 67/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2221 - acc: 0.8960\n",
            "Epoch 68/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2267 - acc: 0.8957\n",
            "Epoch 69/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2313 - acc: 0.8963\n",
            "Epoch 70/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2629 - acc: 0.8911\n",
            "Epoch 71/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2234 - acc: 0.8974\n",
            "Epoch 72/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2134 - acc: 0.8994\n",
            "Epoch 73/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2393 - acc: 0.8913\n",
            "Epoch 74/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2256 - acc: 0.8955\n",
            "Epoch 75/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2549 - acc: 0.8919\n",
            "Epoch 76/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2217 - acc: 0.8972\n",
            "Epoch 77/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2273 - acc: 0.8941\n",
            "Epoch 78/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2127 - acc: 0.8983\n",
            "Epoch 79/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2405 - acc: 0.8950\n",
            "Epoch 80/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2245 - acc: 0.8945\n",
            "Epoch 81/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2209 - acc: 0.8947\n",
            "Epoch 82/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2163 - acc: 0.8972\n",
            "Epoch 83/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2248 - acc: 0.8944\n",
            "Epoch 84/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2051 - acc: 0.9013\n",
            "Epoch 85/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2116 - acc: 0.8983\n",
            "Epoch 86/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2197 - acc: 0.8980\n",
            "Epoch 87/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2339 - acc: 0.8917\n",
            "Epoch 88/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2216 - acc: 0.8987\n",
            "Epoch 89/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2378 - acc: 0.8957\n",
            "Epoch 90/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2260 - acc: 0.8950\n",
            "Epoch 91/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2442 - acc: 0.8945\n",
            "Epoch 92/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2080 - acc: 0.8993\n",
            "Epoch 93/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2243 - acc: 0.8970\n",
            "Epoch 94/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2140 - acc: 0.8986\n",
            "Epoch 95/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2383 - acc: 0.8950\n",
            "Epoch 96/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2163 - acc: 0.8981\n",
            "Epoch 97/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2608 - acc: 0.8918\n",
            "Epoch 98/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2448 - acc: 0.8921\n",
            "Epoch 99/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2379 - acc: 0.8966\n",
            "Epoch 100/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2076 - acc: 0.8996\n",
            "Epoch 101/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2405 - acc: 0.8914\n",
            "Epoch 102/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2171 - acc: 0.8983\n",
            "Epoch 103/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2307 - acc: 0.8963\n",
            "Epoch 104/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2150 - acc: 0.8972\n",
            "Epoch 105/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2272 - acc: 0.8956\n",
            "Epoch 106/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2611 - acc: 0.8902\n",
            "Epoch 107/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2112 - acc: 0.8989\n",
            "Epoch 108/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2275 - acc: 0.8954\n",
            "Epoch 109/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2231 - acc: 0.9006\n",
            "Epoch 110/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2299 - acc: 0.8944\n",
            "Epoch 111/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2234 - acc: 0.8971\n",
            "Epoch 112/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2184 - acc: 0.8972\n",
            "Epoch 113/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2019 - acc: 0.9001\n",
            "Epoch 114/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2256 - acc: 0.8945\n",
            "Epoch 115/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2299 - acc: 0.8966\n",
            "Epoch 116/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2199 - acc: 0.8981\n",
            "Epoch 117/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2192 - acc: 0.8983\n",
            "Epoch 118/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2152 - acc: 0.8975\n",
            "Epoch 119/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2199 - acc: 0.8986\n",
            "Epoch 120/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2139 - acc: 0.8988\n",
            "Epoch 121/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2325 - acc: 0.8961\n",
            "Epoch 122/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2148 - acc: 0.8958\n",
            "Epoch 123/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2169 - acc: 0.8992\n",
            "Epoch 124/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2239 - acc: 0.8978\n",
            "Epoch 125/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2182 - acc: 0.8985\n",
            "Epoch 126/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2389 - acc: 0.8968\n",
            "Epoch 127/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2311 - acc: 0.8961\n",
            "Epoch 128/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2211 - acc: 0.8976\n",
            "Epoch 129/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2284 - acc: 0.8962\n",
            "Epoch 130/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2209 - acc: 0.8956\n",
            "Epoch 131/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2405 - acc: 0.8942\n",
            "Epoch 132/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2145 - acc: 0.8992\n",
            "Epoch 133/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2542 - acc: 0.8948\n",
            "Epoch 134/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2109 - acc: 0.8996\n",
            "Epoch 135/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2097 - acc: 0.8999\n",
            "Epoch 136/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2455 - acc: 0.8931\n",
            "Epoch 137/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2227 - acc: 0.8973\n",
            "Epoch 138/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2148 - acc: 0.9003\n",
            "Epoch 139/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2326 - acc: 0.8956\n",
            "Epoch 140/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2103 - acc: 0.8997\n",
            "Epoch 141/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2239 - acc: 0.8975\n",
            "Epoch 142/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2354 - acc: 0.8966\n",
            "Epoch 143/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2020 - acc: 0.9022\n",
            "Epoch 144/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2157 - acc: 0.8994\n",
            "Epoch 145/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2231 - acc: 0.8970\n",
            "Epoch 146/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2138 - acc: 0.8994\n",
            "Epoch 147/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2286 - acc: 0.8977\n",
            "Epoch 148/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2159 - acc: 0.8993\n",
            "Epoch 149/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2219 - acc: 0.8960\n",
            "Epoch 150/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2403 - acc: 0.8974\n",
            "Epoch 151/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2157 - acc: 0.8984\n",
            "Epoch 152/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2375 - acc: 0.8959\n",
            "Epoch 153/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2092 - acc: 0.8997\n",
            "Epoch 154/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2342 - acc: 0.8946\n",
            "Epoch 155/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2267 - acc: 0.8981\n",
            "Epoch 156/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2165 - acc: 0.8992\n",
            "Epoch 157/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2149 - acc: 0.9008\n",
            "Epoch 158/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2334 - acc: 0.8966\n",
            "Epoch 159/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2060 - acc: 0.9019\n",
            "Epoch 160/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2146 - acc: 0.8995\n",
            "Epoch 161/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2206 - acc: 0.8981\n",
            "Epoch 162/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2251 - acc: 0.8962\n",
            "Epoch 163/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2121 - acc: 0.9000\n",
            "Epoch 164/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2322 - acc: 0.8963\n",
            "Epoch 165/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2075 - acc: 0.9008\n",
            "Epoch 166/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2253 - acc: 0.8969\n",
            "Epoch 167/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2248 - acc: 0.8986\n",
            "Epoch 168/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2199 - acc: 0.8981\n",
            "Epoch 169/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2132 - acc: 0.8995\n",
            "Epoch 170/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2405 - acc: 0.8959\n",
            "Epoch 171/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2117 - acc: 0.9022\n",
            "Epoch 172/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2177 - acc: 0.8991\n",
            "Epoch 173/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2303 - acc: 0.8989\n",
            "Epoch 174/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2119 - acc: 0.9013\n",
            "Epoch 175/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2367 - acc: 0.8954\n",
            "Epoch 176/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2299 - acc: 0.8957\n",
            "Epoch 177/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2082 - acc: 0.9003\n",
            "Epoch 178/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2189 - acc: 0.8994\n",
            "Epoch 179/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2703 - acc: 0.8896\n",
            "Epoch 180/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2144 - acc: 0.9017\n",
            "Epoch 181/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2195 - acc: 0.8985\n",
            "Epoch 182/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2325 - acc: 0.8969\n",
            "Epoch 183/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2138 - acc: 0.9010\n",
            "Epoch 184/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2401 - acc: 0.8945\n",
            "Epoch 185/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2121 - acc: 0.9006\n",
            "Epoch 186/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2295 - acc: 0.8968\n",
            "Epoch 187/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2119 - acc: 0.8987\n",
            "Epoch 188/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2211 - acc: 0.8969\n",
            "Epoch 189/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2218 - acc: 0.8977\n",
            "Epoch 190/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2088 - acc: 0.9006\n",
            "Epoch 191/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2196 - acc: 0.8981\n",
            "Epoch 192/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2189 - acc: 0.8962\n",
            "Epoch 193/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2145 - acc: 0.9007\n",
            "Epoch 194/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2264 - acc: 0.8971\n",
            "Epoch 195/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2094 - acc: 0.9016\n",
            "Epoch 196/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2265 - acc: 0.8967\n",
            "Epoch 197/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2167 - acc: 0.8981\n",
            "Epoch 198/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2123 - acc: 0.9017\n",
            "Epoch 199/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2240 - acc: 0.8984\n",
            "Epoch 200/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2056 - acc: 0.9011\n",
            "Epoch 201/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2183 - acc: 0.9002\n",
            "Epoch 202/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2193 - acc: 0.8994\n",
            "Epoch 203/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2207 - acc: 0.8995\n",
            "Epoch 204/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2180 - acc: 0.8983\n",
            "Epoch 205/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2555 - acc: 0.8952\n",
            "Epoch 206/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2081 - acc: 0.9029\n",
            "Epoch 207/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2472 - acc: 0.8963\n",
            "Epoch 208/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2224 - acc: 0.8992\n",
            "Epoch 209/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2280 - acc: 0.8975\n",
            "Epoch 210/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2402 - acc: 0.8985\n",
            "Epoch 211/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2152 - acc: 0.8999\n",
            "Epoch 212/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2110 - acc: 0.8995\n",
            "Epoch 213/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2079 - acc: 0.9001\n",
            "Epoch 214/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2309 - acc: 0.8965\n",
            "Epoch 215/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2114 - acc: 0.9003\n",
            "Epoch 216/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2145 - acc: 0.8978\n",
            "Epoch 217/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2232 - acc: 0.8990\n",
            "Epoch 218/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2149 - acc: 0.9000\n",
            "Epoch 219/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2185 - acc: 0.8982\n",
            "Epoch 220/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2175 - acc: 0.8985\n",
            "Epoch 221/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2082 - acc: 0.9016\n",
            "Epoch 222/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2371 - acc: 0.8962\n",
            "Epoch 223/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2216 - acc: 0.8999\n",
            "Epoch 224/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2225 - acc: 0.8981\n",
            "Epoch 225/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2119 - acc: 0.9023\n",
            "Epoch 226/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2126 - acc: 0.8996\n",
            "Epoch 227/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2205 - acc: 0.8982\n",
            "Epoch 228/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2134 - acc: 0.9009\n",
            "Epoch 229/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2343 - acc: 0.8979\n",
            "Epoch 230/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2098 - acc: 0.9015\n",
            "Epoch 231/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2202 - acc: 0.8988\n",
            "Epoch 232/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2366 - acc: 0.8975\n",
            "Epoch 233/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2055 - acc: 0.9016\n",
            "Epoch 234/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2274 - acc: 0.8975\n",
            "Epoch 235/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2144 - acc: 0.8992\n",
            "Epoch 236/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2166 - acc: 0.9016\n",
            "Epoch 237/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2031 - acc: 0.9025\n",
            "Epoch 238/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2107 - acc: 0.9003\n",
            "Epoch 239/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2179 - acc: 0.8989\n",
            "Epoch 240/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2149 - acc: 0.9001\n",
            "Epoch 241/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2155 - acc: 0.8998\n",
            "Epoch 242/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2228 - acc: 0.8987\n",
            "Epoch 243/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2279 - acc: 0.8960\n",
            "Epoch 244/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2372 - acc: 0.8985\n",
            "Epoch 245/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2093 - acc: 0.9014\n",
            "Epoch 246/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2155 - acc: 0.9003\n",
            "Epoch 247/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2145 - acc: 0.8992\n",
            "Epoch 248/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2074 - acc: 0.9000\n",
            "Epoch 249/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2386 - acc: 0.8985\n",
            "Epoch 250/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2314 - acc: 0.8970\n",
            "Epoch 251/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2105 - acc: 0.9035\n",
            "Epoch 252/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2329 - acc: 0.8965\n",
            "Epoch 253/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2323 - acc: 0.8950\n",
            "Epoch 254/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2004 - acc: 0.9022\n",
            "Epoch 255/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.1993 - acc: 0.9026\n",
            "Epoch 256/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2232 - acc: 0.9013\n",
            "Epoch 257/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2316 - acc: 0.8980\n",
            "Epoch 258/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2220 - acc: 0.8991\n",
            "Epoch 259/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2012 - acc: 0.9017\n",
            "Epoch 260/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2154 - acc: 0.8999\n",
            "Epoch 261/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2259 - acc: 0.8990\n",
            "Epoch 262/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2115 - acc: 0.9019\n",
            "Epoch 263/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2339 - acc: 0.8974\n",
            "Epoch 264/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2075 - acc: 0.9016\n",
            "Epoch 265/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2340 - acc: 0.8963\n",
            "Epoch 266/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2136 - acc: 0.9009\n",
            "Epoch 267/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2419 - acc: 0.8976\n",
            "Epoch 268/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2229 - acc: 0.8994\n",
            "Epoch 269/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2281 - acc: 0.8976\n",
            "Epoch 270/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2024 - acc: 0.9030\n",
            "Epoch 271/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2421 - acc: 0.8955\n",
            "Epoch 272/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2207 - acc: 0.9022\n",
            "Epoch 273/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2200 - acc: 0.8992\n",
            "Epoch 274/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2177 - acc: 0.8976\n",
            "Epoch 275/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2083 - acc: 0.9021\n",
            "Epoch 276/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2202 - acc: 0.8992\n",
            "Epoch 277/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2046 - acc: 0.9013\n",
            "Epoch 278/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2188 - acc: 0.8976\n",
            "Epoch 279/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2215 - acc: 0.8997\n",
            "Epoch 280/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2128 - acc: 0.9021\n",
            "Epoch 281/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2073 - acc: 0.9022\n",
            "Epoch 282/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2194 - acc: 0.9000\n",
            "Epoch 283/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2129 - acc: 0.9010\n",
            "Epoch 284/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2330 - acc: 0.8978\n",
            "Epoch 285/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2095 - acc: 0.9022\n",
            "Epoch 286/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2122 - acc: 0.9028\n",
            "Epoch 287/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2267 - acc: 0.9004\n",
            "Epoch 288/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2047 - acc: 0.9027\n",
            "Epoch 289/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2286 - acc: 0.8981\n",
            "Epoch 290/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2063 - acc: 0.9031\n",
            "Epoch 291/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2283 - acc: 0.8987\n",
            "Epoch 292/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2302 - acc: 0.9000\n",
            "Epoch 293/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2229 - acc: 0.8991\n",
            "Epoch 294/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2038 - acc: 0.9016\n",
            "Epoch 295/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2308 - acc: 0.8985\n",
            "Epoch 296/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.1993 - acc: 0.9025\n",
            "Epoch 297/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2095 - acc: 0.8998\n",
            "Epoch 298/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2068 - acc: 0.9029\n",
            "Epoch 299/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2120 - acc: 0.8994\n",
            "Epoch 300/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2114 - acc: 0.9027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faeb8152710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L8I-pFNmMM_",
        "colab_type": "code",
        "outputId": "bc86268d-fe78-4fa8-db6c-67c399900c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 [==============================] - 18s 4ms/step - loss: 0.2363 - acc: 0.8928\n",
            "\n",
            "\n",
            "Test Loss 0.23625113713507082, Test Accuracy 0.8928494453430176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A00MBGZ0mU0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(15000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC04en84mVEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_data, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISRe3cpAmVTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXGUYr2imaxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_data.shuffle(15000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSpnnJT3mVpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_data, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP9oo0ZqmV59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}