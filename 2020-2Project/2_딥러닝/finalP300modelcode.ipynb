{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalP300modelcode",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiwk+2dIwfFts/LRKR4Sgg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EEG-Easy/EEG-Machinelearning/blob/master/2020-2Project/2_%EB%94%A5%EB%9F%AC%EB%8B%9D/finalP300modelcode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoScxzhiATIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "from tensorflow import keras\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETAgiD_pA8VF",
        "colab_type": "code",
        "outputId": "42e5c060-d007-46f2-ef6f-03f30f5a2265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-dHbvY8BBl1",
        "colab_type": "code",
        "outputId": "50fd042f-b46f-4bfb-c80b-bafb814e60ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/eeg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/eeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAEv1s2oBF-5",
        "colab_type": "code",
        "outputId": "d497b256-acf5-4587-ab9b-0b4e57db115f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "LABEL_COLUMN = 'group'\n",
        "LABELS = [0, 1]\n",
        "\n",
        "CSV_COLUMNS = ['condition','group', 'F1', 'FC3', 'FC1', 'AFz', 'Fz', 'F2', 'FCz']\n",
        "\n",
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=5, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True, \n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "temp_dataset = get_dataset('RobustP300.csv', select_columns=CSV_COLUMNS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:540: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRlNJEQWBK5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPyl5dRlBNCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['F1', 'FC3', 'FC1', 'AFz', 'Fz', 'F2', 'FCz']\n",
        "\n",
        "packed_data = temp_dataset.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX1J0IIMBPdY",
        "colab_type": "code",
        "outputId": "26ae3dd4-abb4-40a9-b205-cd7646ab5dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "import pandas as pd\n",
        "desc = pd.read_csv('RobustP300.csv')[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>FC3</th>\n",
              "      <th>FC1</th>\n",
              "      <th>AFz</th>\n",
              "      <th>Fz</th>\n",
              "      <th>F2</th>\n",
              "      <th>FCz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "      <td>23201.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.169534</td>\n",
              "      <td>0.147238</td>\n",
              "      <td>0.125680</td>\n",
              "      <td>0.257439</td>\n",
              "      <td>0.161898</td>\n",
              "      <td>0.181233</td>\n",
              "      <td>0.115794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.137716</td>\n",
              "      <td>1.068238</td>\n",
              "      <td>1.004288</td>\n",
              "      <td>1.523621</td>\n",
              "      <td>1.147731</td>\n",
              "      <td>1.186636</td>\n",
              "      <td>0.957781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-8.638409</td>\n",
              "      <td>-7.128760</td>\n",
              "      <td>-6.194677</td>\n",
              "      <td>-10.138734</td>\n",
              "      <td>-7.300168</td>\n",
              "      <td>-7.736735</td>\n",
              "      <td>-6.063609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.450238</td>\n",
              "      <td>-0.453220</td>\n",
              "      <td>-0.460870</td>\n",
              "      <td>-0.440929</td>\n",
              "      <td>-0.455397</td>\n",
              "      <td>-0.448035</td>\n",
              "      <td>-0.462869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.549762</td>\n",
              "      <td>0.546780</td>\n",
              "      <td>0.539130</td>\n",
              "      <td>0.559071</td>\n",
              "      <td>0.544603</td>\n",
              "      <td>0.551965</td>\n",
              "      <td>0.537131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.795594</td>\n",
              "      <td>20.475962</td>\n",
              "      <td>24.351948</td>\n",
              "      <td>25.661585</td>\n",
              "      <td>17.733415</td>\n",
              "      <td>16.691511</td>\n",
              "      <td>13.711209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 F1           FC3  ...            F2           FCz\n",
              "count  23201.000000  23201.000000  ...  23201.000000  23201.000000\n",
              "mean       0.169534      0.147238  ...      0.181233      0.115794\n",
              "std        1.137716      1.068238  ...      1.186636      0.957781\n",
              "min       -8.638409     -7.128760  ...     -7.736735     -6.063609\n",
              "25%       -0.450238     -0.453220  ...     -0.448035     -0.462869\n",
              "50%        0.000000      0.000000  ...      0.000000      0.000000\n",
              "75%        0.549762      0.546780  ...      0.551965      0.537131\n",
              "max       17.795594     20.475962  ...     16.691511     13.711209\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cRFTQ1_BSAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQiEp4WfBULR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs-2zhySBV4o",
        "colab_type": "code",
        "outputId": "fe1c1b7d-699e-4414-9fc0-9f4ae5df727c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(7,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7fa4d47f56a8>, mean=array([0.16953369, 0.14723849, 0.1256803 , 0.25743903, 0.16189793,\n",
              "       0.18123256, 0.11579391]), std=array([1.13771572, 1.06823785, 1.00428802, 1.52362056, 1.14773099,\n",
              "       1.18663606, 0.95778078])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v9ejJ46BXwF",
        "colab_type": "code",
        "outputId": "936b7b4d-194d-478f-f983-ca5f14d52eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "example_batch, labels_batch = next(iter(packed_data)) \n",
        "example_batch['numeric']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=99, shape=(5, 7), dtype=float32, numpy=\n",
              "array([[ 0.56997234,  0.39992845,  0.88199115,  1.2563653 ,  0.865245  ,\n",
              "         0.3329931 ,  0.49335223],\n",
              "       [ 0.2240353 ,  0.41365886,  0.40247983, -0.36064705,  0.06743959,\n",
              "         0.12470734,  0.3182446 ],\n",
              "       [-0.34354183,  0.6368739 , -0.7454713 , -0.80029356, -0.9084039 ,\n",
              "         0.27992165, -1.0512424 ],\n",
              "       [-0.23497479, -0.39232722, -0.19467014, -0.2312169 , -0.28695983,\n",
              "        -0.28301573, -0.089685  ],\n",
              "       [-0.88699013, -1.029036  , -0.41980216, -0.6869951 , -0.8023821 ,\n",
              "        -0.8498319 , -0.7646797 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiaUBjErBaG0",
        "colab_type": "code",
        "outputId": "7b9a9d6b-0585-4c32-ffe2-da84d1834a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.35196725,  0.2365484 ,  0.75308156,  0.65562665,  0.6128153 ,\n",
              "         0.12789139,  0.3942012 ],\n",
              "       [ 0.04790442,  0.24940172,  0.27561766, -0.4056693 , -0.08230007,\n",
              "        -0.04763484,  0.21137477],\n",
              "       [-0.4509699 ,  0.45835802, -0.86743194, -0.69422305, -0.9325372 ,\n",
              "         0.08316711, -1.2184795 ],\n",
              "       [-0.35554442, -0.5050988 , -0.31898263, -0.32072023, -0.39108273,\n",
              "        -0.39123055, -0.21453647],\n",
              "       [-0.928636  , -1.1011354 , -0.54315335, -0.6198617 , -0.8401621 ,\n",
              "        -0.8688969 , -0.91928506]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnDzfqXIBckj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORIES = {'condition': [1, 2, 3]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM8kazmBBe2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKgu7cVwBg7E",
        "colab_type": "code",
        "outputId": "48098fd2-5be7-4a12-8ad4-23561f725136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4271: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4326: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "[0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uhbtb8UBixO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns) #+numeric_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-k3DoonI920",
        "colab_type": "code",
        "outputId": "94c7545f-08ec-4c13-95b3-dffd1abd6fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 체크포인트 콜백 만들기\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "\n",
        "    period=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzAQoMYuBlLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer, # 256,256 / 128,256\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  #tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', optimizer='adam',\n",
        "    metrics=['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYN7zAUKBnNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first 300 epochs with data 20000\n",
        "train_data = packed_data.shuffle(20000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ98kqfCBpdg",
        "colab_type": "code",
        "outputId": "f38fa532-4dc2-4a3c-b1c6-5edcb39d877e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300, callbacks = [cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "4641/4641 [==============================] - 24s 5ms/step - loss: 0.6702 - acc: 0.6012\n",
            "Epoch 2/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6632 - acc: 0.6084\n",
            "Epoch 3/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6599 - acc: 0.6127\n",
            "Epoch 4/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6566 - acc: 0.6161\n",
            "Epoch 5/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6542 - acc: 0.6167\n",
            "Epoch 6/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6515 - acc: 0.6190\n",
            "Epoch 7/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6490 - acc: 0.6206\n",
            "Epoch 8/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6472 - acc: 0.6216\n",
            "Epoch 9/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6454 - acc: 0.6243\n",
            "Epoch 10/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6430 - acc: 0.6261\n",
            "Epoch 11/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6408 - acc: 0.6281\n",
            "Epoch 12/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6397 - acc: 0.6271\n",
            "Epoch 13/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6373 - acc: 0.6283\n",
            "Epoch 14/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6339 - acc: 0.6331\n",
            "Epoch 15/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6330 - acc: 0.6342\n",
            "Epoch 16/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6308 - acc: 0.6361\n",
            "Epoch 17/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6277 - acc: 0.6386\n",
            "Epoch 18/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6264 - acc: 0.6382\n",
            "Epoch 19/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6248 - acc: 0.6420\n",
            "Epoch 20/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6228 - acc: 0.6435\n",
            "Epoch 21/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6205 - acc: 0.6457\n",
            "Epoch 22/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6176 - acc: 0.6483\n",
            "Epoch 23/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6160 - acc: 0.6476\n",
            "Epoch 24/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6137 - acc: 0.6513\n",
            "Epoch 25/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6103 - acc: 0.6512\n",
            "Epoch 26/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6097 - acc: 0.6539\n",
            "Epoch 27/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.6061 - acc: 0.6553\n",
            "Epoch 28/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6027 - acc: 0.6605\n",
            "Epoch 29/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6012 - acc: 0.6602\n",
            "Epoch 30/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.6014 - acc: 0.6621\n",
            "Epoch 31/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5984 - acc: 0.6643\n",
            "Epoch 32/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5946 - acc: 0.6660\n",
            "Epoch 33/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5925 - acc: 0.6686\n",
            "Epoch 34/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5911 - acc: 0.6704\n",
            "Epoch 35/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5885 - acc: 0.6743\n",
            "Epoch 36/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5847 - acc: 0.6738\n",
            "Epoch 37/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5829 - acc: 0.6769\n",
            "Epoch 38/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5829 - acc: 0.6763\n",
            "Epoch 39/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5792 - acc: 0.6794\n",
            "Epoch 40/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5758 - acc: 0.6813\n",
            "Epoch 41/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5744 - acc: 0.6831\n",
            "Epoch 42/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5715 - acc: 0.6857\n",
            "Epoch 43/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5674 - acc: 0.6867\n",
            "Epoch 44/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5671 - acc: 0.6911\n",
            "Epoch 45/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5623 - acc: 0.6920\n",
            "Epoch 46/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5608 - acc: 0.6944\n",
            "Epoch 47/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5578 - acc: 0.6949\n",
            "Epoch 48/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5579 - acc: 0.6946\n",
            "Epoch 49/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5524 - acc: 0.6979\n",
            "Epoch 50/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5517 - acc: 0.6994\n",
            "Epoch 51/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5495 - acc: 0.7001\n",
            "Epoch 52/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5532 - acc: 0.7005\n",
            "Epoch 53/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5469 - acc: 0.7031\n",
            "Epoch 54/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5453 - acc: 0.7045\n",
            "Epoch 55/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5411 - acc: 0.7088\n",
            "Epoch 56/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5453 - acc: 0.7038\n",
            "Epoch 57/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5375 - acc: 0.7085\n",
            "Epoch 58/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5424 - acc: 0.7058\n",
            "Epoch 59/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5325 - acc: 0.7116\n",
            "Epoch 60/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5296 - acc: 0.7123\n",
            "Epoch 61/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5293 - acc: 0.7137\n",
            "Epoch 62/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5322 - acc: 0.7136\n",
            "Epoch 63/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5332 - acc: 0.7146\n",
            "Epoch 64/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5227 - acc: 0.7187\n",
            "Epoch 65/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5228 - acc: 0.7195\n",
            "Epoch 66/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5210 - acc: 0.7198\n",
            "Epoch 67/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5213 - acc: 0.7231\n",
            "Epoch 68/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5239 - acc: 0.7198\n",
            "Epoch 69/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5151 - acc: 0.7223\n",
            "Epoch 70/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5165 - acc: 0.7253\n",
            "Epoch 71/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5124 - acc: 0.7252\n",
            "Epoch 72/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5136 - acc: 0.7294\n",
            "Epoch 73/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5078 - acc: 0.7273\n",
            "Epoch 74/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5045 - acc: 0.7329\n",
            "Epoch 75/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5127 - acc: 0.7279\n",
            "Epoch 76/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5022 - acc: 0.7341\n",
            "Epoch 77/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5032 - acc: 0.7315\n",
            "Epoch 78/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4996 - acc: 0.7343\n",
            "Epoch 79/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4996 - acc: 0.7357\n",
            "Epoch 80/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4978 - acc: 0.7376\n",
            "Epoch 81/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4992 - acc: 0.7362\n",
            "Epoch 82/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4959 - acc: 0.7365\n",
            "Epoch 83/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5007 - acc: 0.7395\n",
            "Epoch 84/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.5035 - acc: 0.7389\n",
            "Epoch 85/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4993 - acc: 0.7395\n",
            "Epoch 86/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4878 - acc: 0.7455\n",
            "Epoch 87/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4891 - acc: 0.7457\n",
            "Epoch 88/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4871 - acc: 0.7447\n",
            "Epoch 89/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4837 - acc: 0.7462\n",
            "Epoch 90/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4812 - acc: 0.7476\n",
            "Epoch 91/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4854 - acc: 0.7459\n",
            "Epoch 92/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4778 - acc: 0.7506\n",
            "Epoch 93/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4795 - acc: 0.7488\n",
            "Epoch 94/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4811 - acc: 0.7488\n",
            "Epoch 95/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4774 - acc: 0.7524\n",
            "Epoch 96/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4706 - acc: 0.7554\n",
            "Epoch 97/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4801 - acc: 0.7512\n",
            "Epoch 98/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4713 - acc: 0.7557\n",
            "Epoch 99/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4797 - acc: 0.7521\n",
            "Epoch 100/300\n",
            "4639/4641 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.7568\n",
            "Epoch 00100: saving model to training_1/cp.ckpt\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4675 - acc: 0.7569\n",
            "Epoch 101/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4697 - acc: 0.7578\n",
            "Epoch 102/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4668 - acc: 0.7583\n",
            "Epoch 103/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4670 - acc: 0.7558\n",
            "Epoch 104/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4631 - acc: 0.7578\n",
            "Epoch 105/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4723 - acc: 0.7566\n",
            "Epoch 106/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4750 - acc: 0.7599\n",
            "Epoch 107/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4643 - acc: 0.7609\n",
            "Epoch 108/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4640 - acc: 0.7617\n",
            "Epoch 109/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4541 - acc: 0.7642\n",
            "Epoch 110/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4560 - acc: 0.7628\n",
            "Epoch 111/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4520 - acc: 0.7657\n",
            "Epoch 112/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4469 - acc: 0.7694\n",
            "Epoch 113/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.4525 - acc: 0.7675\n",
            "Epoch 114/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4590 - acc: 0.7657\n",
            "Epoch 115/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4599 - acc: 0.7642\n",
            "Epoch 116/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4537 - acc: 0.7686\n",
            "Epoch 117/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4472 - acc: 0.7688\n",
            "Epoch 118/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4433 - acc: 0.7725\n",
            "Epoch 119/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4477 - acc: 0.7696\n",
            "Epoch 120/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4430 - acc: 0.7714\n",
            "Epoch 121/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4414 - acc: 0.7725\n",
            "Epoch 122/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4491 - acc: 0.7698\n",
            "Epoch 123/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4441 - acc: 0.7731\n",
            "Epoch 124/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4403 - acc: 0.7760\n",
            "Epoch 125/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4362 - acc: 0.7761\n",
            "Epoch 126/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4360 - acc: 0.7753\n",
            "Epoch 127/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4578 - acc: 0.7703\n",
            "Epoch 128/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4404 - acc: 0.7764\n",
            "Epoch 129/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4424 - acc: 0.7762\n",
            "Epoch 130/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4377 - acc: 0.7795\n",
            "Epoch 131/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4333 - acc: 0.7766\n",
            "Epoch 132/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4372 - acc: 0.7777\n",
            "Epoch 133/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4367 - acc: 0.7791\n",
            "Epoch 134/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4308 - acc: 0.7820\n",
            "Epoch 135/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4260 - acc: 0.7816\n",
            "Epoch 136/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4400 - acc: 0.7761\n",
            "Epoch 137/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4286 - acc: 0.7825\n",
            "Epoch 138/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4371 - acc: 0.7787\n",
            "Epoch 139/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4286 - acc: 0.7813\n",
            "Epoch 140/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4273 - acc: 0.7819\n",
            "Epoch 141/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4223 - acc: 0.7856\n",
            "Epoch 142/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4300 - acc: 0.7805\n",
            "Epoch 143/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4284 - acc: 0.7830\n",
            "Epoch 144/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4253 - acc: 0.7851\n",
            "Epoch 145/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4304 - acc: 0.7843\n",
            "Epoch 146/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4239 - acc: 0.7866\n",
            "Epoch 147/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4223 - acc: 0.7864\n",
            "Epoch 148/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4140 - acc: 0.7916\n",
            "Epoch 149/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4279 - acc: 0.7858\n",
            "Epoch 150/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4155 - acc: 0.7907\n",
            "Epoch 151/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4304 - acc: 0.7844\n",
            "Epoch 152/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4121 - acc: 0.7906\n",
            "Epoch 153/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4196 - acc: 0.7889\n",
            "Epoch 154/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4250 - acc: 0.7879\n",
            "Epoch 155/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4173 - acc: 0.7900\n",
            "Epoch 156/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4255 - acc: 0.7862\n",
            "Epoch 157/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4101 - acc: 0.7918\n",
            "Epoch 158/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4174 - acc: 0.7922\n",
            "Epoch 159/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4090 - acc: 0.7932\n",
            "Epoch 160/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4187 - acc: 0.7923\n",
            "Epoch 161/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4100 - acc: 0.7950\n",
            "Epoch 162/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4166 - acc: 0.7926\n",
            "Epoch 163/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4074 - acc: 0.7952\n",
            "Epoch 164/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4097 - acc: 0.7940\n",
            "Epoch 165/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4034 - acc: 0.7988\n",
            "Epoch 166/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4180 - acc: 0.7943\n",
            "Epoch 167/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4273 - acc: 0.7936\n",
            "Epoch 168/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4084 - acc: 0.7961\n",
            "Epoch 169/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4154 - acc: 0.7942\n",
            "Epoch 170/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4071 - acc: 0.7976\n",
            "Epoch 171/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4071 - acc: 0.7950\n",
            "Epoch 172/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3996 - acc: 0.7984\n",
            "Epoch 173/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3995 - acc: 0.7992\n",
            "Epoch 174/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4039 - acc: 0.7990\n",
            "Epoch 175/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4109 - acc: 0.7953\n",
            "Epoch 176/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3972 - acc: 0.8018\n",
            "Epoch 177/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4080 - acc: 0.8001\n",
            "Epoch 178/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3987 - acc: 0.8000\n",
            "Epoch 179/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3949 - acc: 0.8014\n",
            "Epoch 180/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4009 - acc: 0.8013\n",
            "Epoch 181/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4046 - acc: 0.8017\n",
            "Epoch 182/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3934 - acc: 0.8021\n",
            "Epoch 183/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4013 - acc: 0.8023\n",
            "Epoch 184/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3993 - acc: 0.8039\n",
            "Epoch 185/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4109 - acc: 0.7992\n",
            "Epoch 186/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3840 - acc: 0.8067\n",
            "Epoch 187/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4075 - acc: 0.7983\n",
            "Epoch 188/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3999 - acc: 0.8027\n",
            "Epoch 189/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4046 - acc: 0.8003\n",
            "Epoch 190/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3950 - acc: 0.8033\n",
            "Epoch 191/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3899 - acc: 0.8047\n",
            "Epoch 192/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4121 - acc: 0.8004\n",
            "Epoch 193/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3977 - acc: 0.8027\n",
            "Epoch 194/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3881 - acc: 0.8082\n",
            "Epoch 195/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3917 - acc: 0.8048\n",
            "Epoch 196/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3892 - acc: 0.8059\n",
            "Epoch 197/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3868 - acc: 0.8070\n",
            "Epoch 198/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3836 - acc: 0.8090\n",
            "Epoch 199/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4062 - acc: 0.8020\n",
            "Epoch 200/300\n",
            "4637/4641 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8068\n",
            "Epoch 00200: saving model to training_1/cp.ckpt\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3938 - acc: 0.8069\n",
            "Epoch 201/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3884 - acc: 0.8071\n",
            "Epoch 202/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3776 - acc: 0.8129\n",
            "Epoch 203/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3826 - acc: 0.8086\n",
            "Epoch 204/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4048 - acc: 0.8032\n",
            "Epoch 205/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3906 - acc: 0.8088\n",
            "Epoch 206/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3805 - acc: 0.8118\n",
            "Epoch 207/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3851 - acc: 0.8094\n",
            "Epoch 208/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3985 - acc: 0.8063\n",
            "Epoch 209/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3961 - acc: 0.8044\n",
            "Epoch 210/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3730 - acc: 0.8135\n",
            "Epoch 211/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3963 - acc: 0.8077\n",
            "Epoch 212/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3781 - acc: 0.8123\n",
            "Epoch 213/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3838 - acc: 0.8110\n",
            "Epoch 214/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3892 - acc: 0.8112\n",
            "Epoch 215/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3792 - acc: 0.8137\n",
            "Epoch 216/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3794 - acc: 0.8113\n",
            "Epoch 217/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3740 - acc: 0.8169\n",
            "Epoch 218/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3865 - acc: 0.8087\n",
            "Epoch 219/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3967 - acc: 0.8057\n",
            "Epoch 220/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3861 - acc: 0.8124\n",
            "Epoch 221/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3791 - acc: 0.8136\n",
            "Epoch 222/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3724 - acc: 0.8157\n",
            "Epoch 223/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3719 - acc: 0.8152\n",
            "Epoch 224/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3805 - acc: 0.8148\n",
            "Epoch 225/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3775 - acc: 0.8154\n",
            "Epoch 226/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3818 - acc: 0.8137\n",
            "Epoch 227/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3808 - acc: 0.8131\n",
            "Epoch 228/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3664 - acc: 0.8190\n",
            "Epoch 229/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.3855 - acc: 0.8126\n",
            "Epoch 230/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3717 - acc: 0.8160\n",
            "Epoch 231/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3678 - acc: 0.8191\n",
            "Epoch 232/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3802 - acc: 0.8166\n",
            "Epoch 233/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3718 - acc: 0.8181\n",
            "Epoch 234/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3668 - acc: 0.8193\n",
            "Epoch 235/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3733 - acc: 0.8167\n",
            "Epoch 236/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.4000 - acc: 0.8119\n",
            "Epoch 237/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3773 - acc: 0.8162\n",
            "Epoch 238/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3657 - acc: 0.8237\n",
            "Epoch 239/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3836 - acc: 0.8149\n",
            "Epoch 240/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3947 - acc: 0.8106\n",
            "Epoch 241/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3668 - acc: 0.8207\n",
            "Epoch 242/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3634 - acc: 0.8217\n",
            "Epoch 243/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3672 - acc: 0.8197\n",
            "Epoch 244/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.3622 - acc: 0.8237\n",
            "Epoch 245/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3900 - acc: 0.8159\n",
            "Epoch 246/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3584 - acc: 0.8218\n",
            "Epoch 247/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3653 - acc: 0.8220\n",
            "Epoch 248/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3728 - acc: 0.8209\n",
            "Epoch 249/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3749 - acc: 0.8209\n",
            "Epoch 250/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3713 - acc: 0.8201\n",
            "Epoch 251/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3574 - acc: 0.8244\n",
            "Epoch 252/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3803 - acc: 0.8207\n",
            "Epoch 253/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3580 - acc: 0.8265\n",
            "Epoch 254/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3669 - acc: 0.8208\n",
            "Epoch 255/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3618 - acc: 0.8244\n",
            "Epoch 256/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3654 - acc: 0.8232\n",
            "Epoch 257/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.3633 - acc: 0.8233\n",
            "Epoch 258/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3536 - acc: 0.8266\n",
            "Epoch 259/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3650 - acc: 0.8254\n",
            "Epoch 260/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3662 - acc: 0.8236\n",
            "Epoch 261/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3627 - acc: 0.8237\n",
            "Epoch 262/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3600 - acc: 0.8267\n",
            "Epoch 263/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3682 - acc: 0.8240\n",
            "Epoch 264/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3646 - acc: 0.8242\n",
            "Epoch 265/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3881 - acc: 0.8215\n",
            "Epoch 266/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3772 - acc: 0.8243\n",
            "Epoch 267/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3551 - acc: 0.8261\n",
            "Epoch 268/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3593 - acc: 0.8279\n",
            "Epoch 269/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3595 - acc: 0.8275\n",
            "Epoch 270/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3514 - acc: 0.8277\n",
            "Epoch 271/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3468 - acc: 0.8301\n",
            "Epoch 272/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3683 - acc: 0.8254\n",
            "Epoch 273/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3436 - acc: 0.8322\n",
            "Epoch 274/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3838 - acc: 0.8217\n",
            "Epoch 275/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3808 - acc: 0.8237\n",
            "Epoch 276/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3535 - acc: 0.8273\n",
            "Epoch 277/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3540 - acc: 0.8291\n",
            "Epoch 278/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3585 - acc: 0.8277\n",
            "Epoch 279/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3398 - acc: 0.8315\n",
            "Epoch 280/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3461 - acc: 0.8338\n",
            "Epoch 281/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3567 - acc: 0.8286\n",
            "Epoch 282/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3431 - acc: 0.8318\n",
            "Epoch 283/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3590 - acc: 0.8289\n",
            "Epoch 284/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3523 - acc: 0.8329\n",
            "Epoch 285/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3663 - acc: 0.8284\n",
            "Epoch 286/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3699 - acc: 0.8266\n",
            "Epoch 287/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3415 - acc: 0.8355\n",
            "Epoch 288/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3507 - acc: 0.8307\n",
            "Epoch 289/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3378 - acc: 0.8345\n",
            "Epoch 290/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3477 - acc: 0.8319\n",
            "Epoch 291/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3473 - acc: 0.8300\n",
            "Epoch 292/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3505 - acc: 0.8330\n",
            "Epoch 293/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3429 - acc: 0.8332\n",
            "Epoch 294/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3574 - acc: 0.8316\n",
            "Epoch 295/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3413 - acc: 0.8369\n",
            "Epoch 296/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3508 - acc: 0.8348\n",
            "Epoch 297/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3505 - acc: 0.8316\n",
            "Epoch 298/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3319 - acc: 0.8366\n",
            "Epoch 299/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3349 - acc: 0.8361\n",
            "Epoch 300/300\n",
            "4624/4641 [============================>.] - ETA: 0s - loss: 0.3544 - acc: 0.8313\n",
            "Epoch 00300: saving model to training_1/cp.ckpt\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3539 - acc: 0.8316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9a85f8e710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GvZa0NwJaA5",
        "colab_type": "code",
        "outputId": "32d9050e-9611-4ebb-e888-61cb4a4f9f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data, verbose=2)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 - 6s - loss: 0.5293 - acc: 0.7832\n",
            "\n",
            "\n",
            "Test Loss 0.5292632074737235, Test Accuracy 0.7831990122795105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhj1eqa948mQ",
        "colab_type": "code",
        "outputId": "585ee6ad-f998-4b98-9b77-e289612dd524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model.load_weights(latest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9a82ce70b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noKiXAUs44Gg",
        "colab_type": "code",
        "outputId": "f1d19531-ec7d-413d-9a55-a9d0ce2875d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "checkpoint_path = \"training_2/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 체크포인트 콜백 만들기\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "\n",
        "    period=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeVwe_72B1GX",
        "colab_type": "code",
        "outputId": "6053b003-c793-4b9b-f6b2-79d2457b2190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model.load_weights(latest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f492022e908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6w-LKL65Gxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#second 300 epochs with 10000 data\n",
        "train_data = packed_data.shuffle(10000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr5jKLVC45wJ",
        "colab_type": "code",
        "outputId": "435764ef-94f5-4456-dc20-f51fca1fbcd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300, callbacks = [cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "4641/4641 [==============================] - 29s 6ms/step - loss: 0.3065 - acc: 0.8678\n",
            "Epoch 2/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2809 - acc: 0.8738\n",
            "Epoch 3/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2670 - acc: 0.8749\n",
            "Epoch 4/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2758 - acc: 0.8741\n",
            "Epoch 5/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2685 - acc: 0.8792\n",
            "Epoch 6/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2749 - acc: 0.8759\n",
            "Epoch 7/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2658 - acc: 0.8788\n",
            "Epoch 8/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2596 - acc: 0.8816\n",
            "Epoch 9/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2785 - acc: 0.8762\n",
            "Epoch 10/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2700 - acc: 0.8766\n",
            "Epoch 11/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2532 - acc: 0.8819\n",
            "Epoch 12/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2701 - acc: 0.8769\n",
            "Epoch 13/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2656 - acc: 0.8802\n",
            "Epoch 14/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2572 - acc: 0.8810\n",
            "Epoch 15/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2665 - acc: 0.8810\n",
            "Epoch 16/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2683 - acc: 0.8771\n",
            "Epoch 17/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2661 - acc: 0.8787\n",
            "Epoch 18/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2564 - acc: 0.8794\n",
            "Epoch 19/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2798 - acc: 0.8781\n",
            "Epoch 20/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2610 - acc: 0.8813\n",
            "Epoch 21/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2689 - acc: 0.8804\n",
            "Epoch 22/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2517 - acc: 0.8842\n",
            "Epoch 23/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2580 - acc: 0.8816\n",
            "Epoch 24/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.3132 - acc: 0.8747\n",
            "Epoch 25/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2564 - acc: 0.8833\n",
            "Epoch 26/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2579 - acc: 0.8810\n",
            "Epoch 27/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2633 - acc: 0.8819\n",
            "Epoch 28/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2609 - acc: 0.8807\n",
            "Epoch 29/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2662 - acc: 0.8826\n",
            "Epoch 30/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2522 - acc: 0.8830\n",
            "Epoch 31/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2542 - acc: 0.8831\n",
            "Epoch 32/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2669 - acc: 0.8797\n",
            "Epoch 33/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2470 - acc: 0.8871\n",
            "Epoch 34/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2649 - acc: 0.8813\n",
            "Epoch 35/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2549 - acc: 0.8819\n",
            "Epoch 36/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2427 - acc: 0.8856\n",
            "Epoch 37/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2630 - acc: 0.8821\n",
            "Epoch 38/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2435 - acc: 0.8859\n",
            "Epoch 39/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2768 - acc: 0.8795\n",
            "Epoch 40/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2526 - acc: 0.8852\n",
            "Epoch 41/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2610 - acc: 0.8831\n",
            "Epoch 42/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2490 - acc: 0.8840\n",
            "Epoch 43/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2507 - acc: 0.8851\n",
            "Epoch 44/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2445 - acc: 0.8879\n",
            "Epoch 45/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2587 - acc: 0.8810\n",
            "Epoch 46/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2422 - acc: 0.8869\n",
            "Epoch 47/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2456 - acc: 0.8847\n",
            "Epoch 48/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2667 - acc: 0.8811\n",
            "Epoch 49/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2608 - acc: 0.8832\n",
            "Epoch 50/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2465 - acc: 0.8851\n",
            "Epoch 51/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2423 - acc: 0.8876\n",
            "Epoch 52/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2559 - acc: 0.8842\n",
            "Epoch 53/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2502 - acc: 0.8861\n",
            "Epoch 54/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2437 - acc: 0.8859\n",
            "Epoch 55/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2428 - acc: 0.8881\n",
            "Epoch 56/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2588 - acc: 0.8835\n",
            "Epoch 57/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2330 - acc: 0.8916\n",
            "Epoch 58/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2437 - acc: 0.8879\n",
            "Epoch 59/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2534 - acc: 0.8846\n",
            "Epoch 60/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2632 - acc: 0.8822\n",
            "Epoch 61/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2531 - acc: 0.8855\n",
            "Epoch 62/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2523 - acc: 0.8851\n",
            "Epoch 63/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2530 - acc: 0.8849\n",
            "Epoch 64/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2526 - acc: 0.8866\n",
            "Epoch 65/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2521 - acc: 0.8860\n",
            "Epoch 66/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2431 - acc: 0.8881\n",
            "Epoch 67/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2503 - acc: 0.8857\n",
            "Epoch 68/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2379 - acc: 0.8890\n",
            "Epoch 69/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2655 - acc: 0.8822\n",
            "Epoch 70/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2477 - acc: 0.8882\n",
            "Epoch 71/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2495 - acc: 0.8852\n",
            "Epoch 72/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2670 - acc: 0.8815\n",
            "Epoch 73/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2301 - acc: 0.8928\n",
            "Epoch 74/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2469 - acc: 0.8858\n",
            "Epoch 75/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2373 - acc: 0.8895\n",
            "Epoch 76/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2496 - acc: 0.8869\n",
            "Epoch 77/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2360 - acc: 0.8899\n",
            "Epoch 78/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2495 - acc: 0.8865\n",
            "Epoch 79/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2644 - acc: 0.8849\n",
            "Epoch 80/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2423 - acc: 0.8898\n",
            "Epoch 81/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2319 - acc: 0.8925\n",
            "Epoch 82/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2413 - acc: 0.8896\n",
            "Epoch 83/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2538 - acc: 0.8875\n",
            "Epoch 84/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2483 - acc: 0.8891\n",
            "Epoch 85/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2422 - acc: 0.8903\n",
            "Epoch 86/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2390 - acc: 0.8892\n",
            "Epoch 87/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2331 - acc: 0.8921\n",
            "Epoch 88/300\n",
            "4641/4641 [==============================] - 14s 3ms/step - loss: 0.2451 - acc: 0.8909\n",
            "Epoch 89/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2378 - acc: 0.8912\n",
            "Epoch 90/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2527 - acc: 0.8867\n",
            "Epoch 91/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2424 - acc: 0.8911\n",
            "Epoch 92/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2471 - acc: 0.8882\n",
            "Epoch 93/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2536 - acc: 0.8860\n",
            "Epoch 94/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2496 - acc: 0.8900\n",
            "Epoch 95/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2449 - acc: 0.8879\n",
            "Epoch 96/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2374 - acc: 0.8893\n",
            "Epoch 97/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2352 - acc: 0.8937\n",
            "Epoch 98/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2379 - acc: 0.8905\n",
            "Epoch 99/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2497 - acc: 0.8875\n",
            "Epoch 100/300\n",
            "4631/4641 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.8949\n",
            "Epoch 00100: saving model to training_2/cp.ckpt\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2292 - acc: 0.8947\n",
            "Epoch 101/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2304 - acc: 0.8932\n",
            "Epoch 102/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2336 - acc: 0.8920\n",
            "Epoch 103/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2384 - acc: 0.8919\n",
            "Epoch 104/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2357 - acc: 0.8934\n",
            "Epoch 105/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2429 - acc: 0.8887\n",
            "Epoch 106/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2256 - acc: 0.8946\n",
            "Epoch 107/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2624 - acc: 0.8891\n",
            "Epoch 108/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2279 - acc: 0.8952\n",
            "Epoch 109/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2419 - acc: 0.8916\n",
            "Epoch 110/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2379 - acc: 0.8917\n",
            "Epoch 111/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2427 - acc: 0.8911\n",
            "Epoch 112/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2542 - acc: 0.8882\n",
            "Epoch 113/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2586 - acc: 0.8892\n",
            "Epoch 114/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2359 - acc: 0.8922\n",
            "Epoch 115/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2351 - acc: 0.8923\n",
            "Epoch 116/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2308 - acc: 0.8941\n",
            "Epoch 117/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2470 - acc: 0.8909\n",
            "Epoch 118/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2323 - acc: 0.8920\n",
            "Epoch 119/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2493 - acc: 0.8894\n",
            "Epoch 120/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2320 - acc: 0.8943\n",
            "Epoch 121/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2579 - acc: 0.8892\n",
            "Epoch 122/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2378 - acc: 0.8933\n",
            "Epoch 123/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2245 - acc: 0.8961\n",
            "Epoch 124/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2496 - acc: 0.8897\n",
            "Epoch 125/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2523 - acc: 0.8916\n",
            "Epoch 126/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2195 - acc: 0.8974\n",
            "Epoch 127/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2567 - acc: 0.8882\n",
            "Epoch 128/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2408 - acc: 0.8919\n",
            "Epoch 129/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2472 - acc: 0.8911\n",
            "Epoch 130/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2408 - acc: 0.8931\n",
            "Epoch 131/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2188 - acc: 0.8984\n",
            "Epoch 132/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2649 - acc: 0.8886\n",
            "Epoch 133/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2353 - acc: 0.8935\n",
            "Epoch 134/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2388 - acc: 0.8914\n",
            "Epoch 135/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2274 - acc: 0.8943\n",
            "Epoch 136/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2414 - acc: 0.8947\n",
            "Epoch 137/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2504 - acc: 0.8922\n",
            "Epoch 138/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2500 - acc: 0.8919\n",
            "Epoch 139/300\n",
            "4641/4641 [==============================] - 14s 3ms/step - loss: 0.2315 - acc: 0.8972\n",
            "Epoch 140/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2358 - acc: 0.8940\n",
            "Epoch 141/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2193 - acc: 0.8969\n",
            "Epoch 142/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2374 - acc: 0.8916\n",
            "Epoch 143/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2437 - acc: 0.8904\n",
            "Epoch 144/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2216 - acc: 0.8990\n",
            "Epoch 145/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2395 - acc: 0.8903\n",
            "Epoch 146/300\n",
            "4641/4641 [==============================] - 14s 3ms/step - loss: 0.2291 - acc: 0.8953\n",
            "Epoch 147/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2310 - acc: 0.8941\n",
            "Epoch 148/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2568 - acc: 0.8897\n",
            "Epoch 149/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2338 - acc: 0.8968\n",
            "Epoch 150/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2474 - acc: 0.8908\n",
            "Epoch 151/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2196 - acc: 0.9003\n",
            "Epoch 152/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2311 - acc: 0.8944\n",
            "Epoch 153/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2557 - acc: 0.8890\n",
            "Epoch 154/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2365 - acc: 0.8942\n",
            "Epoch 155/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2631 - acc: 0.8894\n",
            "Epoch 156/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2275 - acc: 0.8959\n",
            "Epoch 157/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2374 - acc: 0.8940\n",
            "Epoch 158/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2344 - acc: 0.8942\n",
            "Epoch 159/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2420 - acc: 0.8938\n",
            "Epoch 160/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2374 - acc: 0.8959\n",
            "Epoch 161/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2404 - acc: 0.8942\n",
            "Epoch 162/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2277 - acc: 0.8976\n",
            "Epoch 163/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2720 - acc: 0.8898\n",
            "Epoch 164/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2311 - acc: 0.8959\n",
            "Epoch 165/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2191 - acc: 0.8985\n",
            "Epoch 166/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2314 - acc: 0.8963\n",
            "Epoch 167/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2271 - acc: 0.8969\n",
            "Epoch 168/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2399 - acc: 0.8941\n",
            "Epoch 169/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2295 - acc: 0.8972\n",
            "Epoch 170/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2604 - acc: 0.8920\n",
            "Epoch 171/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2223 - acc: 0.8999\n",
            "Epoch 172/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2203 - acc: 0.8982\n",
            "Epoch 173/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2622 - acc: 0.8901\n",
            "Epoch 174/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2299 - acc: 0.8981\n",
            "Epoch 175/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2244 - acc: 0.8982\n",
            "Epoch 176/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2621 - acc: 0.8894\n",
            "Epoch 177/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2133 - acc: 0.9013\n",
            "Epoch 178/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2510 - acc: 0.8921\n",
            "Epoch 179/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2377 - acc: 0.8956\n",
            "Epoch 180/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2280 - acc: 0.8981\n",
            "Epoch 181/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2172 - acc: 0.8976\n",
            "Epoch 182/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2527 - acc: 0.8894\n",
            "Epoch 183/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2351 - acc: 0.8959\n",
            "Epoch 184/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2221 - acc: 0.8997\n",
            "Epoch 185/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2156 - acc: 0.9017\n",
            "Epoch 186/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2291 - acc: 0.8973\n",
            "Epoch 187/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2305 - acc: 0.8953\n",
            "Epoch 188/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2213 - acc: 0.9004\n",
            "Epoch 189/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2373 - acc: 0.8975\n",
            "Epoch 190/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2300 - acc: 0.8960\n",
            "Epoch 191/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2170 - acc: 0.8995\n",
            "Epoch 192/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2298 - acc: 0.8962\n",
            "Epoch 193/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2316 - acc: 0.8967\n",
            "Epoch 194/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2233 - acc: 0.8988\n",
            "Epoch 195/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2276 - acc: 0.8978\n",
            "Epoch 196/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2176 - acc: 0.9027\n",
            "Epoch 197/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2418 - acc: 0.8933\n",
            "Epoch 198/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2332 - acc: 0.8965\n",
            "Epoch 199/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2505 - acc: 0.8918\n",
            "Epoch 200/300\n",
            "4640/4641 [============================>.] - ETA: 0s - loss: 0.2315 - acc: 0.8973\n",
            "Epoch 00200: saving model to training_2/cp.ckpt\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2315 - acc: 0.8973\n",
            "Epoch 201/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2243 - acc: 0.8997\n",
            "Epoch 202/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2395 - acc: 0.8954\n",
            "Epoch 203/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2196 - acc: 0.8988\n",
            "Epoch 204/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2203 - acc: 0.8989\n",
            "Epoch 205/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2513 - acc: 0.8943\n",
            "Epoch 206/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2180 - acc: 0.9007\n",
            "Epoch 207/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2377 - acc: 0.8992\n",
            "Epoch 208/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2342 - acc: 0.8960\n",
            "Epoch 209/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2282 - acc: 0.8984\n",
            "Epoch 210/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2217 - acc: 0.8997\n",
            "Epoch 211/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2236 - acc: 0.9016\n",
            "Epoch 212/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2210 - acc: 0.8994\n",
            "Epoch 213/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2623 - acc: 0.8922\n",
            "Epoch 214/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2555 - acc: 0.8952\n",
            "Epoch 215/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2286 - acc: 0.8994\n",
            "Epoch 216/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2347 - acc: 0.8966\n",
            "Epoch 217/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2241 - acc: 0.8994\n",
            "Epoch 218/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2270 - acc: 0.8997\n",
            "Epoch 219/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2188 - acc: 0.8997\n",
            "Epoch 220/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2245 - acc: 0.8995\n",
            "Epoch 221/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2125 - acc: 0.9020\n",
            "Epoch 222/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2328 - acc: 0.8957\n",
            "Epoch 223/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2257 - acc: 0.8989\n",
            "Epoch 224/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2403 - acc: 0.8933\n",
            "Epoch 225/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2150 - acc: 0.9015\n",
            "Epoch 226/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2368 - acc: 0.8996\n",
            "Epoch 227/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2323 - acc: 0.8982\n",
            "Epoch 228/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2397 - acc: 0.8968\n",
            "Epoch 229/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2369 - acc: 0.8973\n",
            "Epoch 230/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2588 - acc: 0.8954\n",
            "Epoch 231/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2208 - acc: 0.9039\n",
            "Epoch 232/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2301 - acc: 0.8985\n",
            "Epoch 233/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2304 - acc: 0.8957\n",
            "Epoch 234/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2141 - acc: 0.9023\n",
            "Epoch 235/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2214 - acc: 0.9015\n",
            "Epoch 236/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2369 - acc: 0.8979\n",
            "Epoch 237/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2447 - acc: 0.8962\n",
            "Epoch 238/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2320 - acc: 0.8991\n",
            "Epoch 239/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2167 - acc: 0.9008\n",
            "Epoch 240/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2075 - acc: 0.9038\n",
            "Epoch 241/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2175 - acc: 0.9014\n",
            "Epoch 242/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2133 - acc: 0.9003\n",
            "Epoch 243/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2286 - acc: 0.8985\n",
            "Epoch 244/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2528 - acc: 0.8945\n",
            "Epoch 245/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2286 - acc: 0.8985\n",
            "Epoch 246/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2251 - acc: 0.8988\n",
            "Epoch 247/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2269 - acc: 0.9000\n",
            "Epoch 248/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2173 - acc: 0.9018\n",
            "Epoch 249/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2484 - acc: 0.8953\n",
            "Epoch 250/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2243 - acc: 0.8996\n",
            "Epoch 251/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2410 - acc: 0.8986\n",
            "Epoch 252/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2096 - acc: 0.9057\n",
            "Epoch 253/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2355 - acc: 0.8983\n",
            "Epoch 254/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2294 - acc: 0.8982\n",
            "Epoch 255/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2408 - acc: 0.8963\n",
            "Epoch 256/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2210 - acc: 0.9016\n",
            "Epoch 257/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2496 - acc: 0.8962\n",
            "Epoch 258/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2210 - acc: 0.9005\n",
            "Epoch 259/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2479 - acc: 0.8943\n",
            "Epoch 260/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2160 - acc: 0.9024\n",
            "Epoch 261/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2180 - acc: 0.9001\n",
            "Epoch 262/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2282 - acc: 0.8994\n",
            "Epoch 263/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2260 - acc: 0.8969\n",
            "Epoch 264/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2258 - acc: 0.8991\n",
            "Epoch 265/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2249 - acc: 0.9007\n",
            "Epoch 266/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2549 - acc: 0.8964\n",
            "Epoch 267/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2086 - acc: 0.9031\n",
            "Epoch 268/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2331 - acc: 0.8989\n",
            "Epoch 269/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2189 - acc: 0.9011\n",
            "Epoch 270/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2190 - acc: 0.9007\n",
            "Epoch 271/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2104 - acc: 0.9036\n",
            "Epoch 272/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2315 - acc: 0.8975\n",
            "Epoch 273/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2345 - acc: 0.8994\n",
            "Epoch 274/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2021 - acc: 0.9070\n",
            "Epoch 275/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2286 - acc: 0.8994\n",
            "Epoch 276/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2444 - acc: 0.8944\n",
            "Epoch 277/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2166 - acc: 0.9024\n",
            "Epoch 278/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2458 - acc: 0.8940\n",
            "Epoch 279/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2230 - acc: 0.9014\n",
            "Epoch 280/300\n",
            "4641/4641 [==============================] - 11s 2ms/step - loss: 0.2134 - acc: 0.9028\n",
            "Epoch 281/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2199 - acc: 0.8982\n",
            "Epoch 282/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2488 - acc: 0.8988\n",
            "Epoch 283/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2382 - acc: 0.8974\n",
            "Epoch 284/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2100 - acc: 0.9047\n",
            "Epoch 285/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2340 - acc: 0.8985\n",
            "Epoch 286/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.2045 - acc: 0.9044\n",
            "Epoch 287/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2409 - acc: 0.8970\n",
            "Epoch 288/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2237 - acc: 0.9007\n",
            "Epoch 289/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2163 - acc: 0.9024\n",
            "Epoch 290/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2088 - acc: 0.9049\n",
            "Epoch 291/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2218 - acc: 0.9014\n",
            "Epoch 292/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2336 - acc: 0.9007\n",
            "Epoch 293/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2156 - acc: 0.9027\n",
            "Epoch 294/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2114 - acc: 0.9029\n",
            "Epoch 295/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2471 - acc: 0.8968\n",
            "Epoch 296/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2158 - acc: 0.9015\n",
            "Epoch 297/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2188 - acc: 0.9035\n",
            "Epoch 298/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2263 - acc: 0.9009\n",
            "Epoch 299/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2563 - acc: 0.8964\n",
            "Epoch 300/300\n",
            "4622/4641 [============================>.] - ETA: 0s - loss: 0.2418 - acc: 0.8986\n",
            "Epoch 00300: saving model to training_2/cp.ckpt\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2419 - acc: 0.8984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49201fc9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDCUg6s84_oV",
        "colab_type": "code",
        "outputId": "18c6b102-4593-4fbc-e832-ad580fb15f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data, verbose=2)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 - 6s - loss: 0.2935 - acc: 0.8853\n",
            "\n",
            "\n",
            "Test Loss 0.2934998929088899, Test Accuracy 0.8853497505187988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vTGsDgY6xYU",
        "colab_type": "code",
        "outputId": "c8cafd21-6f29-4bf3-8a01-fbc97e7ba8bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "checkpoint_path = \"training_3/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 체크포인트 콜백 만들기\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "\n",
        "    period=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erKEm-g4VIfk",
        "colab_type": "code",
        "outputId": "7e86c84c-ae94-4366-ec3b-79905b8b5d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model.load_weights(latest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa4dd522dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMCg1kBz67I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#third 300 epochs x3\n",
        "train_data = packed_data.shuffle(10000)\n",
        "test_data = packed_data.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyYhPLuY68Cp",
        "colab_type": "code",
        "outputId": "69111224-011e-4599-c120-e2f94a3b5294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=300, callbacks = [cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4641/4641 [==============================] - 28s 6ms/step - loss: 0.2080 - acc: 0.9238\n",
            "Epoch 2/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1785 - acc: 0.9294\n",
            "Epoch 3/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1799 - acc: 0.9283\n",
            "Epoch 4/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2064 - acc: 0.9256\n",
            "Epoch 5/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1551 - acc: 0.9325\n",
            "Epoch 6/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1702 - acc: 0.9277\n",
            "Epoch 7/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1529 - acc: 0.9314\n",
            "Epoch 8/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1741 - acc: 0.9297\n",
            "Epoch 9/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1600 - acc: 0.9300\n",
            "Epoch 10/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1770 - acc: 0.9283\n",
            "Epoch 11/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1641 - acc: 0.9312\n",
            "Epoch 12/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1772 - acc: 0.9295\n",
            "Epoch 13/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1546 - acc: 0.9319\n",
            "Epoch 14/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1691 - acc: 0.9288\n",
            "Epoch 15/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1714 - acc: 0.9306\n",
            "Epoch 16/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1600 - acc: 0.9323\n",
            "Epoch 17/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1532 - acc: 0.9319\n",
            "Epoch 18/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2248 - acc: 0.9265\n",
            "Epoch 19/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1715 - acc: 0.9297\n",
            "Epoch 20/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1981 - acc: 0.9278\n",
            "Epoch 21/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1466 - acc: 0.9328\n",
            "Epoch 22/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1610 - acc: 0.9303\n",
            "Epoch 23/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1892 - acc: 0.9285\n",
            "Epoch 24/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1884 - acc: 0.9307\n",
            "Epoch 25/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1685 - acc: 0.9317\n",
            "Epoch 26/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1664 - acc: 0.9302\n",
            "Epoch 27/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1845 - acc: 0.9300\n",
            "Epoch 28/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1624 - acc: 0.9316\n",
            "Epoch 29/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1721 - acc: 0.9303\n",
            "Epoch 30/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1780 - acc: 0.9294\n",
            "Epoch 31/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1584 - acc: 0.9296\n",
            "Epoch 32/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1622 - acc: 0.9311\n",
            "Epoch 33/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1692 - acc: 0.9314\n",
            "Epoch 34/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1598 - acc: 0.9322\n",
            "Epoch 35/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1659 - acc: 0.9310\n",
            "Epoch 36/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1674 - acc: 0.9312\n",
            "Epoch 37/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1803 - acc: 0.9305\n",
            "Epoch 38/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1891 - acc: 0.9288\n",
            "Epoch 39/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1551 - acc: 0.9324\n",
            "Epoch 40/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1705 - acc: 0.9316\n",
            "Epoch 41/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1734 - acc: 0.9325\n",
            "Epoch 42/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1521 - acc: 0.9330\n",
            "Epoch 43/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1731 - acc: 0.9308\n",
            "Epoch 44/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1583 - acc: 0.9299\n",
            "Epoch 45/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1712 - acc: 0.9303\n",
            "Epoch 46/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1351 - acc: 0.9357\n",
            "Epoch 47/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1613 - acc: 0.9300\n",
            "Epoch 48/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1769 - acc: 0.9288\n",
            "Epoch 49/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1552 - acc: 0.9317\n",
            "Epoch 50/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1662 - acc: 0.9306\n",
            "Epoch 51/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1715 - acc: 0.9309\n",
            "Epoch 52/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1593 - acc: 0.9316\n",
            "Epoch 53/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2129 - acc: 0.9257\n",
            "Epoch 54/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1595 - acc: 0.9328\n",
            "Epoch 55/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1541 - acc: 0.9325\n",
            "Epoch 56/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1664 - acc: 0.9304\n",
            "Epoch 57/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1618 - acc: 0.9333\n",
            "Epoch 58/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1648 - acc: 0.9301\n",
            "Epoch 59/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1778 - acc: 0.9321\n",
            "Epoch 60/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1766 - acc: 0.9315\n",
            "Epoch 61/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1728 - acc: 0.9314\n",
            "Epoch 62/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1378 - acc: 0.9360\n",
            "Epoch 63/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1743 - acc: 0.9294\n",
            "Epoch 64/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1533 - acc: 0.9337\n",
            "Epoch 65/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1613 - acc: 0.9305\n",
            "Epoch 66/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1739 - acc: 0.9294\n",
            "Epoch 67/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1574 - acc: 0.9321\n",
            "Epoch 68/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1525 - acc: 0.9327\n",
            "Epoch 69/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1601 - acc: 0.9322\n",
            "Epoch 70/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1530 - acc: 0.9324\n",
            "Epoch 71/300\n",
            "4641/4641 [==============================] - 12s 2ms/step - loss: 0.1773 - acc: 0.9292\n",
            "Epoch 72/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1545 - acc: 0.9322\n",
            "Epoch 73/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2079 - acc: 0.9278\n",
            "Epoch 74/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1439 - acc: 0.9354\n",
            "Epoch 75/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1699 - acc: 0.9291\n",
            "Epoch 76/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1907 - acc: 0.9286\n",
            "Epoch 77/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1425 - acc: 0.9351\n",
            "Epoch 78/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1975 - acc: 0.9286\n",
            "Epoch 79/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1577 - acc: 0.9314\n",
            "Epoch 80/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1552 - acc: 0.9350\n",
            "Epoch 81/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1543 - acc: 0.9335\n",
            "Epoch 82/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1657 - acc: 0.9315\n",
            "Epoch 83/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1552 - acc: 0.9342\n",
            "Epoch 84/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1649 - acc: 0.9308\n",
            "Epoch 85/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1569 - acc: 0.9328\n",
            "Epoch 86/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1841 - acc: 0.9298\n",
            "Epoch 87/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1900 - acc: 0.9297\n",
            "Epoch 88/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1554 - acc: 0.9328\n",
            "Epoch 89/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1699 - acc: 0.9311\n",
            "Epoch 90/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1541 - acc: 0.9314\n",
            "Epoch 91/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1610 - acc: 0.9307\n",
            "Epoch 92/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1646 - acc: 0.9308\n",
            "Epoch 93/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1624 - acc: 0.9306\n",
            "Epoch 94/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1955 - acc: 0.9282\n",
            "Epoch 95/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1606 - acc: 0.9322\n",
            "Epoch 96/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1523 - acc: 0.9346\n",
            "Epoch 97/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1830 - acc: 0.9303\n",
            "Epoch 98/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1833 - acc: 0.9293\n",
            "Epoch 99/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1657 - acc: 0.9321\n",
            "Epoch 100/300\n",
            "4638/4641 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9292\n",
            "Epoch 00100: saving model to training_3/cp.ckpt\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1680 - acc: 0.9292\n",
            "Epoch 101/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1592 - acc: 0.9340\n",
            "Epoch 102/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1564 - acc: 0.9335\n",
            "Epoch 103/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1696 - acc: 0.9314\n",
            "Epoch 104/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1656 - acc: 0.9308\n",
            "Epoch 105/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1696 - acc: 0.9315\n",
            "Epoch 106/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1890 - acc: 0.9302\n",
            "Epoch 107/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1585 - acc: 0.9317\n",
            "Epoch 108/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1474 - acc: 0.9347\n",
            "Epoch 109/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1777 - acc: 0.9305\n",
            "Epoch 110/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1731 - acc: 0.9333\n",
            "Epoch 111/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1713 - acc: 0.9298\n",
            "Epoch 112/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2217 - acc: 0.9259\n",
            "Epoch 113/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1719 - acc: 0.9305\n",
            "Epoch 114/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1507 - acc: 0.9341\n",
            "Epoch 115/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1961 - acc: 0.9279\n",
            "Epoch 116/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1470 - acc: 0.9346\n",
            "Epoch 117/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1563 - acc: 0.9299\n",
            "Epoch 118/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1558 - acc: 0.9310\n",
            "Epoch 119/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1659 - acc: 0.9317\n",
            "Epoch 120/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1927 - acc: 0.9297\n",
            "Epoch 121/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1501 - acc: 0.9332\n",
            "Epoch 122/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1561 - acc: 0.9335\n",
            "Epoch 123/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1558 - acc: 0.9335\n",
            "Epoch 124/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1507 - acc: 0.9335\n",
            "Epoch 125/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1678 - acc: 0.9308\n",
            "Epoch 126/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1820 - acc: 0.9288\n",
            "Epoch 127/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1637 - acc: 0.9339\n",
            "Epoch 128/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1720 - acc: 0.9311\n",
            "Epoch 129/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2440 - acc: 0.9221\n",
            "Epoch 130/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1765 - acc: 0.9311\n",
            "Epoch 131/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1624 - acc: 0.9313\n",
            "Epoch 132/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2032 - acc: 0.9274\n",
            "Epoch 133/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1697 - acc: 0.9334\n",
            "Epoch 134/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1689 - acc: 0.9306\n",
            "Epoch 135/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1428 - acc: 0.9367\n",
            "Epoch 136/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1502 - acc: 0.9334\n",
            "Epoch 137/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1790 - acc: 0.9319\n",
            "Epoch 138/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1548 - acc: 0.9327\n",
            "Epoch 139/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2304 - acc: 0.9285\n",
            "Epoch 140/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1678 - acc: 0.9318\n",
            "Epoch 141/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1761 - acc: 0.9325\n",
            "Epoch 142/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1596 - acc: 0.9328\n",
            "Epoch 143/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1662 - acc: 0.9328\n",
            "Epoch 144/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1625 - acc: 0.9319\n",
            "Epoch 145/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1721 - acc: 0.9309\n",
            "Epoch 146/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1453 - acc: 0.9353\n",
            "Epoch 147/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1690 - acc: 0.9296\n",
            "Epoch 148/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1544 - acc: 0.9322\n",
            "Epoch 149/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1617 - acc: 0.9326\n",
            "Epoch 150/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1512 - acc: 0.9348\n",
            "Epoch 151/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1683 - acc: 0.9320\n",
            "Epoch 152/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1837 - acc: 0.9308\n",
            "Epoch 153/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1655 - acc: 0.9325\n",
            "Epoch 154/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1816 - acc: 0.9288\n",
            "Epoch 155/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1727 - acc: 0.9306\n",
            "Epoch 156/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1567 - acc: 0.9348\n",
            "Epoch 157/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1732 - acc: 0.9319\n",
            "Epoch 158/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1557 - acc: 0.9297\n",
            "Epoch 159/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1552 - acc: 0.9318\n",
            "Epoch 160/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1594 - acc: 0.9290\n",
            "Epoch 161/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1509 - acc: 0.9322\n",
            "Epoch 162/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1804 - acc: 0.9313\n",
            "Epoch 163/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1658 - acc: 0.9328\n",
            "Epoch 164/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1606 - acc: 0.9333\n",
            "Epoch 165/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1648 - acc: 0.9328\n",
            "Epoch 166/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2220 - acc: 0.9292\n",
            "Epoch 167/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1346 - acc: 0.9373\n",
            "Epoch 168/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1607 - acc: 0.9285\n",
            "Epoch 169/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1600 - acc: 0.9328\n",
            "Epoch 170/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1501 - acc: 0.9331\n",
            "Epoch 171/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1630 - acc: 0.9329\n",
            "Epoch 172/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1988 - acc: 0.9289\n",
            "Epoch 173/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1693 - acc: 0.9304\n",
            "Epoch 174/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1765 - acc: 0.9287\n",
            "Epoch 175/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1535 - acc: 0.9333\n",
            "Epoch 176/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1838 - acc: 0.9285\n",
            "Epoch 177/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1325 - acc: 0.9357\n",
            "Epoch 178/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1713 - acc: 0.9309\n",
            "Epoch 179/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1602 - acc: 0.9341\n",
            "Epoch 180/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1667 - acc: 0.9319\n",
            "Epoch 181/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1673 - acc: 0.9318\n",
            "Epoch 182/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1494 - acc: 0.9336\n",
            "Epoch 183/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1578 - acc: 0.9317\n",
            "Epoch 184/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1983 - acc: 0.9272\n",
            "Epoch 185/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1508 - acc: 0.9340\n",
            "Epoch 186/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1537 - acc: 0.9325\n",
            "Epoch 187/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1714 - acc: 0.9312\n",
            "Epoch 188/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1572 - acc: 0.9341\n",
            "Epoch 189/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1491 - acc: 0.9336\n",
            "Epoch 190/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2017 - acc: 0.9272\n",
            "Epoch 191/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1467 - acc: 0.9356\n",
            "Epoch 192/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1729 - acc: 0.9287\n",
            "Epoch 193/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1556 - acc: 0.9324\n",
            "Epoch 194/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1671 - acc: 0.9313\n",
            "Epoch 195/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1682 - acc: 0.9341\n",
            "Epoch 196/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1742 - acc: 0.9317\n",
            "Epoch 197/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1573 - acc: 0.9312\n",
            "Epoch 198/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1434 - acc: 0.9339\n",
            "Epoch 199/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1682 - acc: 0.9312\n",
            "Epoch 200/300\n",
            "4620/4641 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9330\n",
            "Epoch 00200: saving model to training_3/cp.ckpt\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1594 - acc: 0.9331\n",
            "Epoch 201/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1558 - acc: 0.9324\n",
            "Epoch 202/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1634 - acc: 0.9316\n",
            "Epoch 203/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1679 - acc: 0.9325\n",
            "Epoch 204/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1764 - acc: 0.9332\n",
            "Epoch 205/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1648 - acc: 0.9304\n",
            "Epoch 206/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1773 - acc: 0.9296\n",
            "Epoch 207/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1714 - acc: 0.9323\n",
            "Epoch 208/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1489 - acc: 0.9351\n",
            "Epoch 209/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1481 - acc: 0.9330\n",
            "Epoch 210/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1597 - acc: 0.9310\n",
            "Epoch 211/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1609 - acc: 0.9309\n",
            "Epoch 212/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1561 - acc: 0.9324\n",
            "Epoch 213/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1677 - acc: 0.9300\n",
            "Epoch 214/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1642 - acc: 0.9316\n",
            "Epoch 215/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1616 - acc: 0.9349\n",
            "Epoch 216/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1878 - acc: 0.9291\n",
            "Epoch 217/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1622 - acc: 0.9314\n",
            "Epoch 218/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1768 - acc: 0.9317\n",
            "Epoch 219/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2966 - acc: 0.9241\n",
            "Epoch 220/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1468 - acc: 0.9356\n",
            "Epoch 221/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1604 - acc: 0.9310\n",
            "Epoch 222/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1600 - acc: 0.9325\n",
            "Epoch 223/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1630 - acc: 0.9310\n",
            "Epoch 224/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1468 - acc: 0.9363\n",
            "Epoch 225/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1674 - acc: 0.9302\n",
            "Epoch 226/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1677 - acc: 0.9316\n",
            "Epoch 227/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1733 - acc: 0.9316\n",
            "Epoch 228/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1670 - acc: 0.9331\n",
            "Epoch 229/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1472 - acc: 0.9359\n",
            "Epoch 230/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1712 - acc: 0.9305\n",
            "Epoch 231/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1726 - acc: 0.9332\n",
            "Epoch 232/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1534 - acc: 0.9309\n",
            "Epoch 233/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1558 - acc: 0.9342\n",
            "Epoch 234/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1848 - acc: 0.9317\n",
            "Epoch 235/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1602 - acc: 0.9319\n",
            "Epoch 236/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1459 - acc: 0.9345\n",
            "Epoch 237/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1701 - acc: 0.9299\n",
            "Epoch 238/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1573 - acc: 0.9312\n",
            "Epoch 239/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1858 - acc: 0.9288\n",
            "Epoch 240/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1532 - acc: 0.9344\n",
            "Epoch 241/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1525 - acc: 0.9318\n",
            "Epoch 242/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1734 - acc: 0.9297\n",
            "Epoch 243/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1583 - acc: 0.9328\n",
            "Epoch 244/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1578 - acc: 0.9308\n",
            "Epoch 245/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1533 - acc: 0.9315\n",
            "Epoch 246/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1472 - acc: 0.9336\n",
            "Epoch 247/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1886 - acc: 0.9313\n",
            "Epoch 248/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1590 - acc: 0.9326\n",
            "Epoch 249/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1566 - acc: 0.9325\n",
            "Epoch 250/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1526 - acc: 0.9337\n",
            "Epoch 251/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1553 - acc: 0.9319\n",
            "Epoch 252/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1731 - acc: 0.9319\n",
            "Epoch 253/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1461 - acc: 0.9333\n",
            "Epoch 254/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1489 - acc: 0.9363\n",
            "Epoch 255/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1504 - acc: 0.9342\n",
            "Epoch 256/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1677 - acc: 0.9331\n",
            "Epoch 257/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1754 - acc: 0.9297\n",
            "Epoch 258/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1893 - acc: 0.9297\n",
            "Epoch 259/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1612 - acc: 0.9331\n",
            "Epoch 260/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1779 - acc: 0.9298\n",
            "Epoch 261/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2307 - acc: 0.9275\n",
            "Epoch 262/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1439 - acc: 0.9355\n",
            "Epoch 263/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1945 - acc: 0.9298\n",
            "Epoch 264/300\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1431 - acc: 0.9357\n",
            "Epoch 265/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1398 - acc: 0.9375\n",
            "Epoch 266/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1896 - acc: 0.9282\n",
            "Epoch 267/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1683 - acc: 0.9324\n",
            "Epoch 268/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1662 - acc: 0.9322\n",
            "Epoch 269/300\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1833 - acc: 0.9313\n",
            "Epoch 270/300\n",
            "1775/4641 [==========>...................] - ETA: 7s - loss: 0.1945 - acc: 0.9287"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-dbf34fa76046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2WDZt6u7EHz",
        "colab_type": "code",
        "outputId": "8aa1e350-d09d-4081-f375-3cf539876b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data, verbose=2)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 - 6s - loss: 0.1758 - acc: 0.9305\n",
            "\n",
            "\n",
            "Test Loss 0.17581541583844792, Test Accuracy 0.9304771423339844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQLSq-xW74hA",
        "colab_type": "code",
        "outputId": "b8878ff1-5181-4f4e-8073-5298f0e2d21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "checkpoint_path = \"training_4/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 체크포인트 콜백 만들기\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "\n",
        "    period=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwm5a6Ue8DLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#4th 300 epochs\n",
        "train_data = packed_data.shuffle(70000)\n",
        "test_data = packed_data.shuffle(200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQZcSNSW8GVB",
        "colab_type": "code",
        "outputId": "77621e63-cf9f-46b2-844f-c12a5bce2173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, epochs=100, callbacks = [cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4641/4641 [==============================] - 28s 6ms/step - loss: 0.1514 - acc: 0.9328\n",
            "Epoch 2/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1647 - acc: 0.9325\n",
            "Epoch 3/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.2122 - acc: 0.9267\n",
            "Epoch 4/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1611 - acc: 0.9323\n",
            "Epoch 5/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1723 - acc: 0.9297\n",
            "Epoch 6/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1733 - acc: 0.9311\n",
            "Epoch 7/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1594 - acc: 0.9330\n",
            "Epoch 8/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1606 - acc: 0.9320\n",
            "Epoch 9/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1961 - acc: 0.9285\n",
            "Epoch 10/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1479 - acc: 0.9341\n",
            "Epoch 11/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1730 - acc: 0.9296\n",
            "Epoch 12/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1731 - acc: 0.9312\n",
            "Epoch 13/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1686 - acc: 0.9300\n",
            "Epoch 14/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1528 - acc: 0.9336\n",
            "Epoch 15/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1582 - acc: 0.9344\n",
            "Epoch 16/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1904 - acc: 0.9318\n",
            "Epoch 17/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1891 - acc: 0.9324\n",
            "Epoch 18/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1485 - acc: 0.9357\n",
            "Epoch 19/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1760 - acc: 0.9288\n",
            "Epoch 20/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1645 - acc: 0.9321\n",
            "Epoch 21/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1549 - acc: 0.9341\n",
            "Epoch 22/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1467 - acc: 0.9331\n",
            "Epoch 23/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1591 - acc: 0.9316\n",
            "Epoch 24/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1759 - acc: 0.9311\n",
            "Epoch 25/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1575 - acc: 0.9322\n",
            "Epoch 26/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1758 - acc: 0.9326\n",
            "Epoch 27/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1629 - acc: 0.9320\n",
            "Epoch 28/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1819 - acc: 0.9293\n",
            "Epoch 29/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1344 - acc: 0.9363\n",
            "Epoch 30/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1800 - acc: 0.9291\n",
            "Epoch 31/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1416 - acc: 0.9371\n",
            "Epoch 32/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1603 - acc: 0.9324\n",
            "Epoch 33/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1823 - acc: 0.9294\n",
            "Epoch 34/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1434 - acc: 0.9352\n",
            "Epoch 35/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1562 - acc: 0.9326\n",
            "Epoch 36/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1854 - acc: 0.9340\n",
            "Epoch 37/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1629 - acc: 0.9328\n",
            "Epoch 38/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1687 - acc: 0.9328\n",
            "Epoch 39/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1679 - acc: 0.9319\n",
            "Epoch 40/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1601 - acc: 0.9355\n",
            "Epoch 41/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1698 - acc: 0.9303\n",
            "Epoch 42/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1529 - acc: 0.9343\n",
            "Epoch 43/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1833 - acc: 0.9291\n",
            "Epoch 44/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1510 - acc: 0.9352\n",
            "Epoch 45/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1649 - acc: 0.9327\n",
            "Epoch 46/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1641 - acc: 0.9332\n",
            "Epoch 47/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1535 - acc: 0.9336\n",
            "Epoch 48/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1599 - acc: 0.9331\n",
            "Epoch 49/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1593 - acc: 0.9335\n",
            "Epoch 50/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1581 - acc: 0.9325\n",
            "Epoch 51/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1718 - acc: 0.9309\n",
            "Epoch 52/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1495 - acc: 0.9333\n",
            "Epoch 53/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1503 - acc: 0.9348\n",
            "Epoch 54/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1445 - acc: 0.9344\n",
            "Epoch 55/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1551 - acc: 0.9335\n",
            "Epoch 56/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1865 - acc: 0.9303\n",
            "Epoch 57/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1715 - acc: 0.9321\n",
            "Epoch 58/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1983 - acc: 0.9300\n",
            "Epoch 59/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1581 - acc: 0.9322\n",
            "Epoch 60/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1463 - acc: 0.9348\n",
            "Epoch 61/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1720 - acc: 0.9319\n",
            "Epoch 62/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2019 - acc: 0.9321\n",
            "Epoch 63/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1516 - acc: 0.9370\n",
            "Epoch 64/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1854 - acc: 0.9296\n",
            "Epoch 65/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1687 - acc: 0.9327\n",
            "Epoch 66/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1660 - acc: 0.9315\n",
            "Epoch 67/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1597 - acc: 0.9335\n",
            "Epoch 68/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1672 - acc: 0.9318\n",
            "Epoch 69/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1795 - acc: 0.9344\n",
            "Epoch 70/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1548 - acc: 0.9331\n",
            "Epoch 71/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1643 - acc: 0.9348\n",
            "Epoch 72/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1710 - acc: 0.9324\n",
            "Epoch 73/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1865 - acc: 0.9332\n",
            "Epoch 74/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1496 - acc: 0.9363\n",
            "Epoch 75/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1680 - acc: 0.9321\n",
            "Epoch 76/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1695 - acc: 0.9325\n",
            "Epoch 77/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1540 - acc: 0.9343\n",
            "Epoch 78/100\n",
            "4641/4641 [==============================] - 14s 3ms/step - loss: 0.1625 - acc: 0.9320\n",
            "Epoch 79/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1634 - acc: 0.9317\n",
            "Epoch 80/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1617 - acc: 0.9336\n",
            "Epoch 81/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1471 - acc: 0.9349\n",
            "Epoch 82/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1674 - acc: 0.9316\n",
            "Epoch 83/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1550 - acc: 0.9362\n",
            "Epoch 84/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1648 - acc: 0.9344\n",
            "Epoch 85/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1666 - acc: 0.9333\n",
            "Epoch 86/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1452 - acc: 0.9354\n",
            "Epoch 87/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1521 - acc: 0.9343\n",
            "Epoch 88/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1674 - acc: 0.9313\n",
            "Epoch 89/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1783 - acc: 0.9322\n",
            "Epoch 90/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1704 - acc: 0.9334\n",
            "Epoch 91/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1614 - acc: 0.9333\n",
            "Epoch 92/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1517 - acc: 0.9333\n",
            "Epoch 93/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1558 - acc: 0.9326\n",
            "Epoch 94/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1787 - acc: 0.9319\n",
            "Epoch 95/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1493 - acc: 0.9347\n",
            "Epoch 96/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.2096 - acc: 0.9303\n",
            "Epoch 97/100\n",
            "4641/4641 [==============================] - 13s 3ms/step - loss: 0.1778 - acc: 0.9325\n",
            "Epoch 98/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1484 - acc: 0.9351\n",
            "Epoch 99/100\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1819 - acc: 0.9303\n",
            "Epoch 100/100\n",
            "4621/4641 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9332\n",
            "Epoch 00100: saving model to training_4/cp.ckpt\n",
            "4641/4641 [==============================] - 12s 3ms/step - loss: 0.1630 - acc: 0.9334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa4d0374320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb6KRvAV8JDr",
        "colab_type": "code",
        "outputId": "fb58a1b7-62c9-422b-bdad-1f1ab7ed39a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data, verbose=2)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4641/4641 - 6s - loss: 0.1750 - acc: 0.9320\n",
            "\n",
            "\n",
            "Test Loss 0.17497062047196152, Test Accuracy 0.9319856762886047\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}